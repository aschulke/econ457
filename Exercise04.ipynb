{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log, exp, sqrt\n",
    "from scipy.stats import gamma as Gamma_Distribution\n",
    "from scipy.special import psi\n",
    "from scipy.special import gamma as Gamma_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulate some data\n",
    "n, k = 500, 3\n",
    "beta = np.arange(k) + 0.5\n",
    "X = np.random.rand(n, k)\n",
    "mu = X.dot(beta)\n",
    "p = np.random.rand(n)\n",
    "y = - mu * np.log(1 - p)\n",
    "# plt.figure()\n",
    "# plt.hist(y,n/20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logL(beta, X, y):\n",
    "    u = X.dot(beta)\n",
    "    l = - (y/u) - log(u)\n",
    "    return l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myqnewton(f, x0, B, searchmeth = 3,stepmeth = \"bt\" ,maxit = 10000, maxstep = 10000,tol = 1/100000,\\\n",
    "              eps = np.spacing(1),eps0 =1.0, eps1 = 1.e-12, all_x = False):\n",
    "    '''\n",
    "    maxit, maxstep, tol,eps0, eps1  = 10000, 10000, 1/10000,1.0,1.e-12\n",
    "    f: object function and jacobian\n",
    "    B:  inversed Hessian matrix  \n",
    "    x0: initial value\n",
    "    all_x: if we collect x value for plotting\n",
    "    '''\n",
    "    x = x0\n",
    "    if all_x:\n",
    "        x_list = [x0]\n",
    "        \n",
    "    \n",
    "    A = f(x)\n",
    "    _is_there_jacobian = (type(A) is tuple) and (len(A) == 2)\n",
    "\n",
    "    if _is_there_jacobian:\n",
    "        print('Jacobian was provided by user!')\n",
    "        fx0,g0 = f(x)\n",
    "    else:    \n",
    "        print('Jacobian was not provided by user!')\n",
    "        fx0 = f(x)\n",
    "        try:\n",
    "            g0 = jacobian(f,x)\n",
    "        except NameError:\n",
    "            print(\"jacobian function Not in scope!\\n Using identity matrix as jacobian matrix\")\n",
    "            g0 = np.identity(k)\n",
    "        else:\n",
    "            print(\"jacobian function In scope!\")    \n",
    "        \n",
    "    if np.all(np.abs(g0) < eps): # similar to np.all(g0<eps)\n",
    "        print(\"abs(g0)< eps...\")\n",
    "        return x\n",
    "    \n",
    "    print(\"Solving nonlinear equations by using {} search method and {} step method\".format(search_methods[searchmeth-1].capitalize(), stepmeth)) \n",
    "\n",
    "    print(\"Start iteration......\")\n",
    "   \n",
    "\n",
    "    for it in range(maxit):\n",
    "\n",
    "\n",
    "        d = -np.dot(B, g0)  # search direction, initial d\n",
    "        \n",
    "        # https://github.com/randall-romero/CompEcon-python/blob/master/compecon/optimize.py\n",
    "        if (np.inner(d, g0) / (np.inner(d, d))) < eps1:  # must go uphill\n",
    "            B =  -np.identity(k) / np.maximum(abs(fx0), 1) # otherwise use\n",
    "            d = g0 / np.maximum(np.abs(fx0), 1)  # steepest ascent\n",
    "        # optimize search step length\n",
    "        s, fx = optstep(stepmeth ,f, x, fx0, g0, d, maxstep)\n",
    "\n",
    "        if fx <= fx0:\n",
    "\n",
    "            warnings.warn('Iterations stuck in qnewton')\n",
    "            #return x\n",
    "            # reset Hessian and d.\n",
    "            B =  -np.identity(k) / np.maximum(abs(fx0), 1) # otherwise use\n",
    "            d = g0.T / np.maximum(abs(fx0), 1)  # steepest ascent\n",
    "            s, fx = optstep(\"bt\" ,f, x, fx0, g0, d, maxstep)\n",
    "            if errcode:\n",
    "                warnings.warn('Cannot find suitable step in qnewton')\n",
    "                # return x\n",
    "                # reset to 1 and fx0\n",
    "                s, fx =  1, fx0\n",
    "\n",
    "        # update d and x\n",
    "        d *= s\n",
    "        x = x + d\n",
    "        # keep record of x sequence in list\n",
    "        if all_x:\n",
    "            x_list.append(x.copy())\n",
    "\n",
    "        if np.any(np.isnan(x) | np.isinf(x)):\n",
    "            raise ValueError('NaNs or Infs encountered')\n",
    "\n",
    "        #  update fx and g again\n",
    "        if _is_there_jacobian:\n",
    "            #print('Jacobian was provided by user!')\n",
    "            fx,g = f(x)\n",
    "        else:    \n",
    "            print('Jacobian was not provided by user!')\n",
    "            fx = f(x)\n",
    "            try:\n",
    "                g = jacobian(f,x)\n",
    "            except NameError:\n",
    "                print(\"jacobian function Not in scope!\\n Using identity matrix as jacobian matrix\")\n",
    "                g = np.identity(k)\n",
    "            else:\n",
    "                print(\"jacobian function In scope!\")\n",
    "\n",
    "\n",
    "        # Test convergence using Marquardt's criteria and gradient test\n",
    "        if ((fx - fx0) / (abs(fx) + eps0) < tol and\n",
    "                np.all(np.abs(d) / (np.abs(x) + eps0) < tol)) or\\\n",
    "                np.all(np.abs(g) < eps):\n",
    "                print(\"Meet the tol. x: \", x)\n",
    "                #break\n",
    "                if all_x:\n",
    "                    return x, x_list\n",
    "                else:\n",
    "                    return x\n",
    "\n",
    "\n",
    "\n",
    "        # Update inverse Hessian\n",
    "        u = g - g0  # change in Jacobian\n",
    "        ud = np.inner(u, d)\n",
    "\n",
    "        # pick a search method\n",
    "        #print(\"Please specify one search method: 1:steepest ascen;2: DFP;3:BFGS\")\n",
    "        if np.all(np.abs(ud) < eps):\n",
    "            B =  -np.identity(k) / np.maximum(abs(fx0), 1) # otherwise use\n",
    "        else:\n",
    "            if searchmeth == 1 and np.abs(ud) < eps: # steepest ascent\n",
    "                B =  -np.identity(k) / np.maximum(abs(fx), 1)\n",
    "            elif searchmeth == 2: # DFP\n",
    "                v = B.dot(u)\n",
    "                B += np.outer(d, d) / ud - np.outer(v, v) / np.inner(u, v) \n",
    "            elif searchmeth == 3: # BFGS\n",
    "                w = d - B.dot(u)\n",
    "                wd = np.outer(w, d)\n",
    "                B += ((wd + wd.T) - (np.inner(u, w) * np.outer(d, d)) / ud) / ud\n",
    "\n",
    "\n",
    "        # Update iteration\n",
    "        fx0 = fx\n",
    "        g0 = g\n",
    "        print(\"finish {}th iteration...\".format(it))   \n",
    "\n",
    "    # end of iteration if exceed the maxit\n",
    "    if it >= maxit:\n",
    "        warnings.warn('Maximum iterations exceeded in qnewton')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = OP(logL, np.ones(k),X, y)\n",
    "beta_hat = myqnewton(logL, np.ones(k),X, y)\n",
    "print('Looking for the maximum likelihood:    beta = ', beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dlogL(beta, X, y):\n",
    "    u = X.dot(beta)\n",
    "    temp = ((y - u) / u ** 2)\n",
    "    dl = temp[:, np.newaxis] * X\n",
    "    return dl.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# simulate some data\n",
    "n = 500\n",
    "a = 5.0\n",
    "b = 2.0\n",
    "x_data = Gamma_Distribution.rvs(a, scale=1/b, size=n)\n",
    "Y1 = x_data.mean()\n",
    "Y2 = exp(log(x_data).mean())\n",
    "b_hat = lambda a0: a0 / Y1\n",
    "def dlogL(theta):\n",
    "    return log(theta) - log(Y1 / Y2) - psi(theta)\n",
    "a0 = 1.1 # initial guess\n",
    "\n",
    "estimator = NLP(dlogL, a0, print=True, all_x=True)\n",
    "\n",
    "\n",
    "\n",
    "# estimator = MCP(dlogL, 0, np.inf, a0, print=True, all_x=True)\n",
    "a_hat = estimator.zero()\n",
    "print(estimator.x_sequence)\n",
    "print(b_hat(estimator.x_sequence))\n",
    "y1y2 = np.linspace(1.1, 3, 48)\n",
    "dlogL2 = lambda theta, y12: log(theta) - log(y12) - psi(theta)\n",
    "ttheta = np.array([NLP(dlogL2, a0, k).zero() for k in y1y2])\n",
    "plt.figure()\n",
    "plt.plot(y1y2, ttheta)\n",
    "plt.xlabel('Y1 / Y2')\n",
    "plt.ylabel('theta1')\n",
    "plt.show()\n",
    "# Solve it using the MLE object\n",
    "def logL(theta, x):\n",
    "    n = x.size\n",
    "    a, b = theta\n",
    "    return n*a*log(b) + (a-1)*log(x).sum() - b*x.sum() - n*log(Gamma_Function(a))\n",
    "mle = MLE(logL, np.ones(2), x_data)\n",
    "mle.estimate()\n",
    "print('theta1 = {:.4f}, theta1 = {:.4f}'.format(*mle.beta))\n",
    "print('Estimated Covariance = \\n', mle.Sigma)\n",
    "print('Confidence intervals\\n', mle.ci())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "treasury_tau = np.array([0.25, 0.5, 1, 2, 3, 5, 7, 10, 30])\n",
    "\n",
    "treasury_r = np.array(\n",
    "    [[4.44, 4.49, 4.51, 4.63, 4.63, 4.62, 4.82, 4.77, 5.23],\n",
    "     [4.45, 4.48, 4.49, 4.61, 4.61, 4.60, 4.84, 4.74, 5.16],\n",
    "     [4.37, 4.49, 4.53, 4.66, 4.66, 4.65, 4.86, 4.76, 5.18],\n",
    "     [4.47, 4.47, 4.51, 4.57, 4.57, 4.57, 4.74, 4.68, 5.14]])\n",
    "\n",
    "\n",
    "def Z(r, t, k, a, s):\n",
    "    gamma = sqrt(k **2 + 2 * s ** 2)\n",
    "    egt = exp(gamma * t) - 1\n",
    "\n",
    "    numA = 2 * gamma * exp((gamma + k) * t / 2)\n",
    "    numB = 2*egt\n",
    "    den = (gamma + k) * egt + 2 * gamma\n",
    "    expA = 2 * k * a / (s ** 2)\n",
    "    A = (numA / den) ** expA\n",
    "    B = numB / den\n",
    "    Z = A * exp(-B * r)\n",
    "    return Z\n",
    "\n",
    "def ss(x, r, tau):\n",
    "    k, a, s = x\n",
    "    resid = r + 100 * log(Z(r / 100, tau, k, a, s)) / tau\n",
    "    return -(resid ** 2).sum()\n",
    "\n",
    "\n",
    "def ss2(x, r, tau):\n",
    "    tmp = lambda x: ss(x, r, tau)\n",
    "    return jacobian(tmp, x)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x0 = np.array([0.51, 0.05, 0.12])\n",
    "\n",
    "hola = MCP(ss2, np.zeros(3), np.ones(3), x0, treasury_r[0], treasury_tau)\n",
    "x = hola.zero(print=True)\n",
    "print(x)\n",
    "\n",
    "objective = OP(ss, x0, treasury_r[0], treasury_tau)\n",
    "objective.qnewton(print=True, all_x=True)\n",
    "print(objective.x)\n",
    "print(objective.fnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
