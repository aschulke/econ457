{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "# Numerical Integration and Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many computational economic applications, one must compute the definite integral\n",
    "of a real-valued function f with respect to a \"weighting\" function w over an interval\n",
    "$I$ of $R^n$:\n",
    "\n",
    "$$\\int_I f(x)w(x) dx$$\n",
    "\n",
    "\n",
    "The weighting function may be the identity, $w = 1$, in which case the integral represents\n",
    "the area under the function f. In other applications, w may be the probability\n",
    "density of a random variable $\\tilde X$\n",
    ", in which case the integral represents the expectation\n",
    "of $f( \\tilde X)$ when $I$ repesents the whole support of $\\tilde X$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n= 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we discuss three classes of numerical integration or numerical\n",
    "quadrature methods<sup>1</sup>. All methods approximate the integral with a weighted sum of\n",
    "function values:\n",
    "\n",
    "$$\\int_I f(x) w(x)dx \\approx \\sum_{i=0}^{n} w_i f(x_i)\\thinspace .$$\n",
    "\n",
    "<sup>1</sup>Quadrature is a historical mathematical term that means calculating area. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods differ only in how the *quadrature weights* $wi$ and the *quadrature nodes*\n",
    "$xi$ are chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Newton-Cotes rules employ piecewise polynomial approximations to the integrand\n",
    "2. Gaussian quadrature methods employ nodes and weights that satisfy moment matching conditions\n",
    "3. Monte Carlo methods employ equally weighted “random” nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Newton-Cotes** methods approximate the integrand f between nodes\n",
    "using low order polynomials, and sum the integrals of the polynomials to estimate\n",
    "the integral of f. Newton-Cotes methods are easy to implement, but are not particularly\n",
    "eÆcient for computing the integral of a smooth function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian quadrature**\n",
    "methods choose the nodes and weights to satisfy moment matching conditions, and\n",
    "are more powerful than Newton-Cotes methods if the integrand is smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monte Carlo and quasi-Monte Carlo integration** methods use \"random\" or \"equidistributed\"\n",
    "nodes, and are simple to implement and are especially useful if the integration domain\n",
    "is of high dimension or irregularly shaped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we also present an overview of how to compute *finite difference*\n",
    "approximations for the derivatives of a real-valued function. \n",
    "\n",
    "As we have seen in\n",
    "previous chapters, it is often desirable to compute derivatives numerically because\n",
    "analytic derivative expressions are difficult or impossible to derive, or expensive to\n",
    "evaluate. \n",
    "\n",
    "Finite difference methods can also be used to solve differential equations,\n",
    "which arise frequently in dynamic economic models, especially models formulated in\n",
    "continuous time. In this chapter, we introduce numerical methods for differential\n",
    "equations and illustrate their application to *initial value problems*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/QuantEcon/QuantEcon.py/blob/488b7b3b9117cfd9bfc71c187efc87c39fc5b459/quantecon/quad.py\n",
    "\"\"\"\n",
    "Filename: quad.py\n",
    "Authors: Chase Coleman, Spencer Lyon\n",
    "Date: 2014-07-01\n",
    "Defining various quadrature routines.\n",
    "Based on the quadrature routines found in the CompEcon toolbox by\n",
    "Miranda and Fackler.\n",
    "References\n",
    "----------\n",
    "Miranda, Mario J, and Paul L Fackler. Applied Computational Economics\n",
    "and Finance, MIT Press, 2002.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "from scipy.special import gammaln\n",
    "import sympy as sym\n",
    "#from .ce_util import ckron, gridmake\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ckron(*arrays):\n",
    "    \"\"\"\n",
    "    Repeatedly applies the np.kron function to an arbitrary number of\n",
    "    input arrays\n",
    "    Parameters\n",
    "    ----------\n",
    "    *arrays : tuple/list of np.ndarray\n",
    "    Returns\n",
    "    -------\n",
    "    out : np.ndarray\n",
    "        The result of repeated kronecker products\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function `ckron` in CompEcon toolbox by Miranda\n",
    "    and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return reduce(np.kron, arrays)\n",
    "\n",
    "def gridmake(*arrays):\n",
    "    \"\"\"\n",
    "    TODO: finish this docstring\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``gridmake`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational Economics\n",
    "    and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if all([i.ndim == 1 for i in arrays]):\n",
    "        d = len(arrays)\n",
    "        if d == 2:\n",
    "            out = _gridmake2(*arrays)\n",
    "        else:\n",
    "            out = _gridmake2(arrays[0], arrays[1])\n",
    "            for arr in arrays[2:]:\n",
    "                out = _gridmake2(out, arr)\n",
    "\n",
    "        return out\n",
    "    else:\n",
    "        raise NotImplementedError(\"Come back here\")\n",
    "\n",
    "        \n",
    "def _gridmake2(x1, x2):\n",
    "    \"\"\"\n",
    "    TODO: finish this docstring\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``gridmake2`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational Economics\n",
    "    and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if x1.ndim == 1 and x2.ndim == 1:\n",
    "        return np.column_stack([np.tile(x1, x2.shape[0]),\n",
    "                               np.repeat(x2, x1.shape[0])])\n",
    "    elif x1.ndim > 1 and x2.ndim == 1:\n",
    "        first = np.tile(x1, (x2.shape[0], 1))\n",
    "        second = np.repeat(x2, x1.shape[0])\n",
    "        return np.column_stack([first, second])\n",
    "    else:\n",
    "        raise NotImplementedError(\"Come back here\")        \n",
    "\n",
    "def _qnwtrap1(n, a, b):\n",
    "    \"\"\"\n",
    "    Compute univariate trapezoid rule quadrature nodes and weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    a : int\n",
    "        The lower endpoint\n",
    "    b : int\n",
    "        The upper endpoint\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwtrap1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "\n",
    "    nodes = np.linspace(a, b, n)\n",
    "    dx = nodes[1] - nodes[0]\n",
    "\n",
    "    weights = dx * np.ones(n)\n",
    "    weights[0] *= 0.5\n",
    "    weights[-1] *= 0.5\n",
    "\n",
    "    return nodes, weights\n",
    "        \n",
    "\n",
    "def _qnwsimp1(n, a, b):\n",
    "    \"\"\"\n",
    "    Compute univariate Simpson quadrature nodes and weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    a : int\n",
    "        The lower endpoint\n",
    "    b : int\n",
    "        The upper endpoint\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwsimp1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if n % 2 == 0:\n",
    "        print(\"WARNING qnwsimp: n must be an odd integer. Increasing by 1\")\n",
    "        n += 1\n",
    "\n",
    "    nodes = np.linspace(a, b, n)\n",
    "    dx = nodes[1] - nodes[0]\n",
    "    weights = np.tile([2.0, 4.0], (n + 1) // 2)\n",
    "    weights = weights[:n]\n",
    "    weights[0] = weights[-1] = 1\n",
    "    weights = (dx / 3.0) * weights\n",
    "\n",
    "    return nodes, weights    \n",
    "    \n",
    "        \n",
    "def _qnwlege1(n, a, b):\n",
    "    \"\"\"\n",
    "    Compute univariate Guass-Legendre quadrature nodes and weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    a : int\n",
    "        The lower endpoint\n",
    "    b : int\n",
    "        The upper endpoint\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwlege1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    maxit = 100\n",
    "    m = np.fix((n + 1) / 2.0).astype(int)\n",
    "    xm = 0.5 * (b + a)\n",
    "    xl = 0.5 * (b - a)\n",
    "    nodes = np.zeros(n)\n",
    "\n",
    "    weights = nodes.copy()\n",
    "    i = np.arange(m, dtype='int')\n",
    "\n",
    "    z = np.cos(np.pi * ((i + 1.0) - 0.25) / (n + 0.5))\n",
    "\n",
    "    for its in range(maxit):\n",
    "        p1 = 1.0\n",
    "        p2 = 0.0\n",
    "        for j in range(1, n+1):\n",
    "            p3 = p2\n",
    "            p2 = p1\n",
    "            p1 = ((2 * j - 1) * z * p2 - (j - 1) * p3) / j\n",
    "\n",
    "        pp = n * (z * p1 - p2)/(z * z - 1.0)\n",
    "        z1 = z.copy()\n",
    "        z = z1 - p1/pp\n",
    "        if all(np.abs(z - z1) < 1e-14):\n",
    "            break\n",
    "\n",
    "    if its == maxit - 1:\n",
    "        raise ValueError(\"Maximum iterations in _qnwlege1\")\n",
    "\n",
    "    nodes[i] = xm - xl * z\n",
    "    nodes[- i - 1] = xm + xl * z\n",
    "\n",
    "    weights[i] = 2 * xl / ((1 - z * z) * pp * pp)\n",
    "    weights[- i - 1] = weights[i]\n",
    "\n",
    "    return nodes, weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def _make_multidim_func(one_d_func, n, *args):\n",
    "    \"\"\"\n",
    "    A helper function to cut down on code repetition. Almost all of the\n",
    "    code in qnwcheb, qnwlege, qnwsimp, qnwtrap is just dealing\n",
    "    various forms of input arguments and then shelling out to the\n",
    "    corresponding 1d version of the function.\n",
    "    This routine does all the argument checking and passes things\n",
    "    through the appropriate 1d function before using a tensor product\n",
    "    to combine weights and nodes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    one_d_func : function\n",
    "        The 1d function to be called along each dimension\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    args :\n",
    "        These are the arguments to various qnw____ functions.  For the\n",
    "        majority of the functions this is just a and b, but some differ.\n",
    "    Returns\n",
    "    -------\n",
    "    func : function\n",
    "        The multi-dimensional version of the parameter ``one_d_func``\n",
    "    \"\"\"\n",
    "    args = list(args)\n",
    "    n = np.asarray(n)\n",
    "    args = list(map(np.asarray, args))\n",
    "\n",
    "    if all([x.size == 1 for x in [n] + args]):\n",
    "        return one_d_func(n, *args)\n",
    "\n",
    "    d = n.size\n",
    "\n",
    "    for i in range(len(args)):\n",
    "        if args[i].size == 1:\n",
    "            args[i] = np.repeat(args[i], d)\n",
    "\n",
    "    nodes = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(d):\n",
    "        ai = [x[i] for x in args]\n",
    "        _1d = one_d_func(n[i], *ai)\n",
    "        nodes.append(_1d[0])\n",
    "        weights.append(_1d[1])\n",
    "\n",
    "    weights = ckron(*weights[::-1])  # reverse ordered tensor product\n",
    "\n",
    "    nodes = gridmake(*nodes)\n",
    "    return nodes, weights    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Newton-Cotes Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reference: \n",
    "\n",
    "\n",
    "https://nbviewer.jupyter.org/github/birocoles/Disciplina-metodos-computacionais/blob/master/Content/newton-cotes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton-Cotes quadrature methods are designed to approximate the integral of a realvalued\n",
    "function $f$ defined on a bounded interval $[a; b]$ of the real line. Newton-Cotes\n",
    "methods approximate the integrand $f$ between nodes using *low order polynomials*,\n",
    "and sum the integrals of the polynomials to form an estimate the integral of f. \n",
    "\n",
    "Two\n",
    "Newton-Cotes rules are widely used in practice: the **trapezoid rule and Simpson's\n",
    "rule**. Both rules are very easy to implement and are typically adequate for computing\n",
    "the area under a continuous function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Trapezoid rule (based on piecewise linear approximation) \n",
    "2. Simpson’s rule (based on piecewise quadratic approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trapezoid Rule\n",
    "\n",
    "![](http://mathworld.wolfram.com/images/eps-gif/TrapezoidalRule_1000.gif)\n",
    "\n",
    "http://mathworld.wolfram.com/Newton-CotesFormulas.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Newton%E2%80%93Cotes_formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trapezoid rule partitions the interval [a; b] into subintervals of equal length, approximates\n",
    "f over each subinterval using linear interpolants, and then sums the areas under the\n",
    "linear segments. The trapezoid rule draws its name from the fact that the area under f is\n",
    "approximated by a series of trapezoids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\int \\limits_{x_i}^{x_{i+1}} f \\, (x) \\, d x \\approx \\frac{h}{2} \\left[ f(x_i) + f(x_{i+1})  \\right]\\: .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $x_i = a + (i-1)h$, with $h$ (called the step size) equal to   $ h=(b − a) / (n-1)$. The $w_i$ are called weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int _{a}^{b}f(x)\\,dx\\approx \\sum _{{i=1}}^{{n-1}}w_{i}\\,f(x_{i}).$$\n",
    "\n",
    "\n",
    "where $w_1 = w_n = h/2$ and $w_i = h$, otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCompute the function values $f(x_{i})$\tat the nodes\n",
    "2.\tForm a piecewise linear approximation $\\tilde f$ of $f$ \tby connecting successive points $(x_i,y_i)$ on the graph of $f$\twith straight lines\n",
    "3.\tThe area under $f$  is then approximated by the area under $\\tilde f$ , which consists of a series of trapezoids, giving the trapezoid rule its name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example \n",
    "\n",
    "First, we define a simple function and sample it between 0 and 10 at 200 points\n",
    "\n",
    "\n",
    "reference:\n",
    "\n",
    "http://nbviewer.jupyter.org/github/sbustamante/ComputationalMethods/blob/master/material/numerical-calculus.ipynb#Numerical-Differentiation\n",
    "\n",
    "https://github.com/ipython/ipython/blob/master/examples/IPython%20Kernel/Trapezoid%20Rule.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quadrature method\n",
    "def Quadrature( f, X, xmin, xmax, ymin=0, ymax=1, fig=None, leg=True ):\n",
    "    #f(x_i) values\n",
    "    Y = f( X )\n",
    "    \n",
    "    #X array\n",
    "    Xarray = np.linspace( xmin, xmax, 1000 )\n",
    "    #X area\n",
    "    Xarea = np.linspace( X[0], X[-1], 1000 )\n",
    "    #F array\n",
    "    Yarray = f( Xarray )\n",
    "    \n",
    "    #Lagrange polynomial\n",
    "    Ln = interp.lagrange( X, Y )\n",
    "    #Interpolated array\n",
    "    Parray = Ln( Xarray )\n",
    "    #Interpolated array for area\n",
    "    Parea = Ln( Xarea )\n",
    "    \n",
    "    #Plotting\n",
    "    if fig==None:\n",
    "        fig = plt.figure( figsize = (8,8) )\n",
    "    ax = fig.add_subplot(111)\n",
    "    #Function\n",
    "    ax.plot( Xarray, Yarray, linewidth = 3, color = \"blue\", label=\"$f(x)$\" )\n",
    "    #Points\n",
    "    ax.plot( X, Y, \"o\", color=\"red\", label=\"points\", zorder = 10 )\n",
    "    #Interpolator\n",
    "    ax.plot( Xarray, Parray, linewidth = 2, color = \"black\", label=\"$P_{%d}(x)$\"%(len(X)-1) )\n",
    "    #Area\n",
    "    ax.fill_between( Xarea, Parea, color=\"green\", alpha=0.5 )\n",
    "    \n",
    "    #Format\n",
    "    ax.set_title( \"%d-point Quadrature\"%(len(X)), fontsize=16 )\n",
    "    ax.set_xlim( (xmin, xmax) )\n",
    "    ax.set_ylim( (ymin, ymax) )\n",
    "    ax.set_xlabel( \"$x$\" )\n",
    "    ax.set_ylabel( \"$y$\" )\n",
    "    if leg:\n",
    "        ax.legend( loc=\"upper left\", fontsize=16 )\n",
    "    ax.grid(1)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "def f(x):\n",
    "    return 1+np.cos(x)**2+x\n",
    "\n",
    "# Choose a region to integrate over and take only a few points in that region\n",
    "#Quadrature with 2 points (Trapezoidal rule)\n",
    "\n",
    "X = np.array([-0.5,1.5])\n",
    "\n",
    "#Interpolation add-on\n",
    "import scipy.interpolate as interp\n",
    "# Plot both the function and the area below it in the trapezoid approximation\n",
    "Quadrature( f, X, xmin=-1, xmax=2, ymin=0, ymax=3.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite trapezoidal rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula is obtained when we subdivide the integration interval $[a,b]$ within sets of two points, such that we can apply the previous Trapezoidal rule to each one.\n",
    "\n",
    "Let $f(x)$ be a well behaved function ($f\\in C^2[a,b]$), defining the interval space as $h = (b-a)/N$, where N is the number of intervals we take, the **Composite Trapezoidal rule** is given by:\n",
    "\n",
    "$$ \\int_a^b f(x) dx = \\frac{h}{2}\\left[ f(a) + 2\\sum_{j=1}^{N-1}f(x_j) + f(b) \\right] - \\frac{b-a}{12}h^2 f^{''}(\\mu)$$\n",
    "\n",
    "for some value $\\mu$ in $(a,b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Composite Quadrature method\n",
    "def CompositeQuadrature( f, a, b, N, n, xmin, xmax, ymin=0, ymax=1 ):\n",
    "    #X array\n",
    "    X = np.linspace( a, b, N )\n",
    "    \n",
    "    #Plotting\n",
    "    fig = plt.figure( figsize = (8,8) )\n",
    "    for i in range(0,N-n,n):\n",
    "        Xi = X[i:i+n+1]\n",
    "        ax = Quadrature( f, Xi, X[i], X[i+n], fig=fig, leg=False )\n",
    "    \n",
    "    #X array\n",
    "    Xarray = np.linspace( xmin, xmax, 1000 )\n",
    "    #F array\n",
    "    Yarray = f( Xarray )\n",
    "    #Function\n",
    "    ax.plot( Xarray, Yarray, linewidth = 3, color = \"blue\", label=\"$f(x)$\", zorder=0 )\n",
    "    ax.set_title( \"%d-point Quadrature\"%(N), fontsize=16 )\n",
    "    #Format\n",
    "    plt.xlim( (xmin, xmax) )\n",
    "    plt.ylim( (ymin, ymax) )\n",
    "    \n",
    "    return None\n",
    "\n",
    "#Quadrature with 3 points (Simpson's rule)\n",
    "CompositeQuadrature( f, a=-0.5, b=1.5, N=5, n=1, xmin=-1, xmax=2, ymin=0, ymax=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%latex\n",
    "\\begin{align}\n",
    "\\int_a^b f(x)\\,dx &= \\int_{x_0}^{x_1} f(x) dx + \\int_{x_1}^{x_2} f(x) dx + \\ldots + \\int_{x_{n-1}}^{x_n} f(x) dx,     \\nonumber \\\\ \n",
    "                  &\\approx h \\frac{f(x_0) + f(x_1)}{2} +\n",
    "\t\t  h \\frac{f(x_1) + f(x_2)}{2} + \\ldots + \\nonumber \\\\ \n",
    "\t\t  &\\quad h \\frac{f(x_{n-1}) + f(x_n)}{2} \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\\int_a^b f(x)\\,dx \\approx  \n",
    "\\frac{h}{2}\\left[f(x_0) + 2 f(x_1) + 2 f(x_2) + \\ldots + 2 f(x_{n-1}) + f(x_n)\\right]              \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\int_a^b f(x)\\,dx \\approx h \\left[\\frac{1}{2}f(x_0) + \\sum_{i=1}^{n-1}f(x_i) + \\frac{1}{2}f(x_n) \\right] \\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, when $n = 2$\n",
    "\n",
    "\n",
    "$${\\frac  {b-a}{2}}(f_{0}+f_{1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trapezoidal(f, a, b, n):\n",
    "    h = float(b-a)/n\n",
    "    result = 0.5*f(a) + 0.5*f(b)\n",
    "    for i in range(1, n):\n",
    "        result += f(a + i*h)\n",
    "    result *= h\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -.5\n",
    "b = 1.5\n",
    "#  first look at the scipy\n",
    "from scipy.integrate import quad\n",
    "integral, error = quad(f, a, b)\n",
    "print(\"The integral is:\", integral, \"+/-\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "# now look at our function\n",
    "\n",
    "\n",
    "integral_trapezoid = trapezoidal(f, a, b, n)\n",
    "\n",
    "print(\"The trapezoid approximation with\", (n+1), \"points is:\", integral_trapezoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "integral_trapezoid = trapezoidal(f, a, b, n)\n",
    "\n",
    "print(\"The trapezoid approximation with\", (n+1), \"points is:\", integral_trapezoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _qnwtrap1(n, a, b):\n",
    "    \"\"\"\n",
    "    Compute univariate trapezoid rule quadrature nodes and weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    a : int\n",
    "        The lower endpoint\n",
    "    b : int\n",
    "        The upper endpoint\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwtrap1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if n < 1:\n",
    "        raise ValueError(\"n must be at least one\")\n",
    "\n",
    "    nodes = np.linspace(a, b, n)\n",
    "    dx = nodes[1] - nodes[0]\n",
    "\n",
    "    weights = dx * np.ones(n)\n",
    "    weights[0] *= 0.5\n",
    "    weights[-1] *= 0.5\n",
    "\n",
    "    return nodes, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The trapezoid rule is simple and robust. \n",
    "\n",
    "- It is said to be first order exact because, if\n",
    "not for rounding error, it will exactly compute the integral of any first order polynomial,\n",
    "that is, a line. \n",
    "\n",
    "- In general, if the integrand f is smooth, the trapezoid rule will yield an\n",
    "approximation error that is $O(h^2)$, that is, the error shrinks quadratically with the width of\n",
    "the subintervals.\n",
    "\n",
    "- Doubling the nodes reduces the error by a factor of four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwtrap(n, a, b):\n",
    "    \"\"\"\n",
    "    Computes multivariate trapezoid rule quadrature nodes and weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwtrap`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return _make_multidim_func(_qnwtrap1, n, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qnwtrap and qnwsimp generate quadrature nodes and weights for trapezoid rule as follows\n",
    "a = -.5\n",
    "b = 1.5\n",
    "n = 5 # greater than 1\n",
    "x,w = qnwtrap(n,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs \n",
    "\n",
    "1. n the number of nodes \n",
    "\n",
    "2. a the left integration limit \n",
    "\n",
    "3.  b the right integration limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Outputs\n",
    "1.  x and w, the n× 1 vectors of quadrature nodes and weights, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "For example, to compute the probability that a standard normal random variable is less than 1, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda  x: np.exp(-x**2/2)/np.sqrt(2*np.pi)\n",
    "n = 22; a = 0; b = 1 \n",
    "x,w = qnwtrap(n,a,b) \n",
    "prob = 0.5 + w@f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed answer, 0.8413, is correct to four significant digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpson's rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpson's rule is based on piece-wise quadratic, rather than piece-wise linear, approximations\n",
    "to the integrand $f$.\n",
    "\n",
    "\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Simpsons_method_illustration.svg/440px-Simpsons_method_illustration.svg.png)\n",
    "\n",
    "`Simpson's rule can be derived by approximating the integrand f (x) (in blue) by the quadratic interpolant P(x) (in red).`\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Simpson%27s_rule\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a piecewise quadratic approximation of by connecting successive triplets of graph points ( $\\left[ \\, f(x_{2j-1}) ,\\, f(x_{2j}) ,\\, f(x_{2j+1}) \\, \\right]$), with  quadratic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under this quadratic function provides an estimate of the area under f over the\n",
    "subinterval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int \\limits_{x_{2j-1}}^{x_{2j+1}} f(x)\\, d x \\approx \\frac{h}{3} \\left[ \\, f(x_{2j-1}) + 4 \\, f(x_{2j}) + f(x_{2j+1}) \\, \\right]$$\n",
    "\n",
    "- where $x_i = a + (i-1)h$, \n",
    "- with $h$ (called the step size) equal to   $ h=(b − a) / (n-1)$ and n is odd. \n",
    "- The $w_i$ are called weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up the areas under the quadratic approximants across subintervals yields Simpson's\n",
    "rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_a^b f(x)dx \\approx \\sum_{i=0}^{n-1} w_if(x_i)\\thinspace .$$\n",
    "\n",
    "- where $w_1 = w_n = h/3$ \n",
    "- and, otherwise, $w_i = 4h/3$ if i is even \n",
    "- and $w_i = 2h/3$ if i is odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadrature with 3 points (Simpson's rule)\n",
    "X = np.array([-0.5,0.5,1.5])\n",
    "# change the y-lim to 0-1\n",
    "Quadrature( f, X, xmin=-1, xmax=2, ymin=0, ymax=0.6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More formally, let $x_i = a + (i - 1)h$ for $i = 1; 2; ... ; n$, where\n",
    "$ h=(b − a) / (n-1)$ and $n$ is odd. The nodes $x_i$ divide the interval $[a; b]$ into an even number\n",
    "$n - 1$ of subintervals of equal length $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite Simpson's rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we instead divide the integration interval in sets of three points, we can apply Simpson's rule to each one, obtaining:\n",
    "\n",
    "$$ \\int_a^bf(x)dx = \\frac{h}{3}\\left[ f(a) +2 \\sum_{j=1}^{(n/2)-1}f(x_{2j})+4\\sum_{j=1}^{n/2}f(x_{2j-1})+f(b) \\right] - \\frac{b-a}{180}h^4f^{(4)}(\\mu)$$\n",
    "\n",
    "for some value $\\mu$ in $(a,b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Simpson's rule is as simple as the trapezoid rule, and thus not much harder to program.\n",
    "Even though Simpson's rule is based on *locally quadratic approximation* of the integrand,\n",
    "it is *third order exact*. That is, it exactly computes the integral of any cubic polynomial.\n",
    "In general, if the integrand is smooth, Simpson's rule yields an approximation error that is\n",
    "$O(h^4)$, and thus falls at twice the geometric rate of the error associated with the trapezoid\n",
    "rule.\n",
    "\n",
    "\n",
    "*Simpson's rule is preferred to the trapezoid rule* when the integrand $f$ is smooth because\n",
    "it retains the algorithmic simplicity of the trapezoid rule while offering **twice the degree of\n",
    "approximation**. However, the trapezoid rule will often be more accurate than Simpson's rule\n",
    "if the integrand exhibits **discontinuities in its first derivative**, which can occur in economic\n",
    "applications exhibiting corner solutions. Newton-Cotes rules based on fourth and higher\n",
    "order piecewise polynomial approximations exist, but are more difficult to work with and\n",
    "thus are rarely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quadrature with 3 points (Simpson's rule)\n",
    "CompositeQuadrature( f, a=-0.5, b=1.5, N=5, n=2, xmin=-1, xmax=2, ymin=0, ymax=0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Simpson's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _qnwsimp1(n, a, b):\n",
    "    \"\"\"\n",
    "    Compute univariate Simpson quadrature nodes and weights\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    a : int\n",
    "        The lower endpoint\n",
    "    b : int\n",
    "        The upper endpoint\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwsimp1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if n % 2 == 0:\n",
    "        print(\"WARNING qnwsimp: n must be an odd integer. Increasing by 1\")\n",
    "        n += 1\n",
    "\n",
    "    nodes = np.linspace(a, b, n)\n",
    "    dx = nodes[1] - nodes[0]\n",
    "    weights = np.tile([2.0, 4.0], (n + 1) // 2)\n",
    "    weights = weights[:n]\n",
    "    weights[0] = weights[-1] = 1\n",
    "    weights = (dx / 3.0) * weights\n",
    "\n",
    "    return nodes, weights    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the use of tensor product principles, univariate Newton-Cotes quadrature schemes\n",
    "can be generalized for higher dimensional integration.\n",
    "\n",
    "\n",
    "This construction\n",
    "principle can be applied to an arbitrary dimension using repeated tensor product operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwsimp(n, a, b):\n",
    "    \"\"\"\n",
    "    Computes multivariate Simpson quadrature nodes and weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwsimp`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return _make_multidim_func(_qnwsimp1, n, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If is smooth, the Simpson’s rule approximation error is proportional to $h^4$\n",
    "\n",
    "2. Doubling the nodes reduces the error by a factor of sixteen\n",
    "\n",
    "3. Simpson’s rule is preferred to the trapezoid rule because it is almost as simple, but far more accurate\n",
    "\n",
    "4. Newton-Cotes rules based on piecewise polynomials of third and higher degree can be defined, but are not practical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qnwtrap and qnwsimp generate quadrature nodes and weights for Simpson rule as follows\n",
    "a = -.5\n",
    "b = 1.5\n",
    "n = 3 # n must be an odd integer\n",
    "x,w = qnwsimp(n,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  for normal cdf \n",
    "f = lambda  x: np.exp(-x**2/2)/np.sqrt(2*np.pi)\n",
    "n = 11; a = 0; b = 1 \n",
    "x,w = qnwsimp(n,a,b) \n",
    "prob = 0.5 + w@f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qnwsimp uses less nodes than qntrap with the same accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In most computational economic applications it is not possible to determine a priori\n",
    "how many partition points are needed to compute an integral to a desired level of accuracy\n",
    "using a Newton-Cotes quadrature rule. One solution to this problem is to use an **adaptive\n",
    "quadrature strategy** whereby one increases the number of points at which the integrand is\n",
    "evaluated until the sequence of estimates of the integral converge. Efficient adaptive Newton-\n",
    "Cotes quadrature schemes are especially easy to implement. One simple, but powerful,\n",
    "scheme calls for the number of intervals to be doubled with each iteration. Because the new\n",
    "partition points include the partition points used in the previous iteration, the computational\n",
    "effort required to form the new integral estimate is cut in half. More sophisticated adaptive\n",
    "Newton-Cotes quadrature techniques relax the requirement that the intervals be equally\n",
    "spaced and concentrate new evaluation points in those areas where the integrand appears to\n",
    "be most irregular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Adaptive Quadrature Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the integrate of the function $f(x) = e^{-3x}\\sin(4x)$ within the interval $[0,4]$, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "def f(x):\n",
    "    return np.exp(-3*x)*np.sin(4*x)\n",
    "\n",
    "#Plotting\n",
    "X = np.linspace( 0, 4, 200 )\n",
    "Y = f(X)\n",
    "plt.figure( figsize=(14,7) )\n",
    "plt.plot( X, Y, color=\"blue\", lw=3 )\n",
    "plt.fill_between( X, Y, color=\"blue\", alpha=0.5 )\n",
    "plt.xlim( 0,4 )\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using composite numerical integration is not completely adequate for this problem as the function exhibits different behaviours for differente intervals. For the interval $[0,2]$ the function varies noticeably, requiring a rather small integration interval $h$. However, for the interval $[2,4]$ variations are not considerable and low-order composite integration is enough. This lays a pathological situation where simple composite methods are not efficient. In order to remedy this, we introduce an adaptive quadrature methods, where the integration step $h$ can vary according to the interval. The main advantage of this is a controlable precision of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5.2 Gaussian Quadrature\n",
    "Gaussian quadrature rules are constructed with respect to specific weighting functions.\n",
    "\n",
    "\n",
    "Specifically, for a weighting function $w$ defined on an interval $I \\in R$ of the real\n",
    "line, and for a given order of approximation n, the quadrature nodes $x_1; x_2; ... ; x_n$\n",
    "and quadrature weights $w_1; w_2; ...; w_n$ are chosen so as to satisfy the **$2n$ \"moment-matching\"\n",
    "conditions:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\int_I x^k w(x)dx = \\sum_{i=1}^{n} w_i x_i^k\\thinspace \\forall \\thinspace k = 0,...,2n-1. $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The integral approximation is then computed by forming the prescribed weighted sum of\n",
    "function values at the prescribed nodes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_I f(x) w(x) \\thinspace dx \\approx \\sum_{i=1}^{n} w_i f(x_i)\\thinspace .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By construction, an n-point Gaussian quadrature rule is order $2n - 1$ exact. That is, if not\n",
    "for rounding error, it will exactly compute the integral of any polynomial of order $2n - 1$ \n",
    "or less with respect to the weight function. Thus, if f can be closely approximated by a\n",
    "polynomial, Gaussian quadrature should provide an accurate approximation to the integral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Comparison_Gaussquad_trapezoidal.svg/880px-Comparison_Gaussquad_trapezoidal.svg.png)\n",
    "\n",
    "\n",
    "\n",
    "*Comparison between 2-point Gaussian and trapezoidal quadrature. The blue line is the polynomial ${\\displaystyle y(x)=7x^{3}-8x^{2}-3x+3}$ , whose integral in [−1, 1] is 2/3. The trapezoidal rule returns the integral of the orange dashed line, equal to ${\\displaystyle y(-1)+y(1)=-10} $. The 2-point Gaussian quadrature rule returns the integral of the black dashed curve, equal to ${\\displaystyle y(-{\\sqrt {\\scriptstyle 1/3}})+y({\\sqrt {\\scriptstyle 1/3}})=2/3}$. Such a result is exact, since the green region has the same area as the red regions.*\n",
    "\n",
    "reference\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gaussian_quadrature\n",
    "\n",
    "http://mathworld.wolfram.com/GaussianQuadrature.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most applications of Gaussian quadrature involve computing the expectation of a function $f$ of a continuous random variable $\\tilde X$ with known probability density function $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Legendre quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian quadrature over a bounded interval with respect to the identity weight function,\n",
    "$w(x) \\equiv 1$, is called **Gauss-Legendre quadrature**. Gauss-Legendre quadrature is special\n",
    "interest because it is the Gaussian quadrature scheme appropriate for computing the area\n",
    "under a curve. Gauss-Legendre quadrature is consistent for Riemann integrable functions.\n",
    "That is, if f is Riemann integrable, then the approximation afforded by Gauss-Legendre\n",
    "quadrature can be made arbitrarily precise by increasing the number of nodes n.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the weight function w is the **probability density function** of some continuous random\n",
    "variable $\\tilde X$\n",
    ", Gaussian quadrature has a very straightforward interpretation. In this\n",
    "context, Gaussian quadrature essentially **\"discretizes\" the continuous random variable $\\tilde X$**\n",
    "by\n",
    "replacing it with a discrete random variable with mass points $x_i$ and probabilities $w_i$ that\n",
    "approximates $\\tilde X$\n",
    "in the sense that both random variables have the same moments of order\n",
    "less than 2n:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sum_{i=1}^{n} w_i x_i^k = E \\tilde X^k   \\thinspace \\forall \\thinspace k = 0,...,2n-1. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Given the mass points and probabilities of the **discrete approximant**, the expectation of any\n",
    "function of the **continuous random variable $\\tilde X$**\n",
    "may be approximated using the expectation of\n",
    "the function of the discrete approximant, which requires only the computation of a weighted\n",
    "sum:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ E f(\\tilde X) = \\int_I f(x) w(x) \\thinspace dx \\approx \\sum_{i=1}^{n} w_i f(x_i)\\thinspace .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Computing the n-degree Gaussian nodes and weights is a non-trivial task which involves solving the $2n$ nonlinear equations for ${x_i}$ and ${w_i}$. \n",
    "\n",
    "2. Effcient, specialized numerical routines for computing Gaussian quadrature nodes and weights are available for different weight functions, including virtually all the better known probability distributions such as the uniform, normal, gamma, exponential, Chi-square, and beta distributions.\n",
    "\n",
    "3. All utilities generate mass points $x$ and probabilities $w$ as output, and require the number of mass points n as input, but differ with respect to other inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _qnwnorm1(n):\n",
    "    \"\"\"\n",
    "    Compute nodes and weights for quadrature of univariate standard\n",
    "    normal distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        The number of nodes\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of nodes\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        An n element array of weights\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwnorm1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    maxit = 100\n",
    "    pim4 = 1 / np.pi**(0.25)\n",
    "    m = np.fix((n + 1) / 2).astype(int)\n",
    "    nodes = np.zeros(n)\n",
    "    weights = np.zeros(n)\n",
    "\n",
    "    for i in range(m):\n",
    "        if i == 0:\n",
    "            z = np.sqrt(2*n+1) - 1.85575 * ((2 * n + 1)**(-1 / 6.1))\n",
    "        elif i == 1:\n",
    "            z = z - 1.14 * (n ** 0.426) / z\n",
    "        elif i == 2:\n",
    "            z = 1.86 * z + 0.86 * nodes[0]\n",
    "        elif i == 3:\n",
    "            z = 1.91 * z + 0.91 * nodes[1]\n",
    "        else:\n",
    "            z = 2 * z + nodes[i-2]\n",
    "\n",
    "        its = 0\n",
    "\n",
    "        while its < maxit:\n",
    "            its += 1\n",
    "            p1 = pim4\n",
    "            p2 = 0\n",
    "            for j in range(1, n+1):\n",
    "                p3 = p2\n",
    "                p2 = p1\n",
    "                p1 = z * math.sqrt(2.0/j) * p2 - math.sqrt((j - 1.0) / j) * p3\n",
    "\n",
    "            pp = math.sqrt(2 * n) * p2\n",
    "            z1 = z\n",
    "            z = z1 - p1/pp\n",
    "            if abs(z - z1) < 1e-14:\n",
    "                break\n",
    "\n",
    "        if its == maxit:\n",
    "            raise ValueError(\"Failed to converge in _qnwnorm1\")\n",
    "\n",
    "        nodes[n - 1 - i] = z\n",
    "        nodes[i] = -z\n",
    "        weights[i] = 2 / (pp*pp)\n",
    "        weights[n - 1 - i] = weights[i]\n",
    "\n",
    "    weights /= math.sqrt(math.pi)\n",
    "    nodes = nodes * math.sqrt(2.0)\n",
    "\n",
    "    return nodes, weights\n",
    "\n",
    "def _qnwbeta1(n, a=1.0, b=1.0):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for quadrature on the beta distribution.\n",
    "    Default is a=b=1 which is just a uniform distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : scalar : int\n",
    "        The number of quadrature points\n",
    "    a : scalar : float, optional(default=1)\n",
    "        First Beta distribution parameter\n",
    "    b : scalar : float, optional(default=1)\n",
    "        Second Beta distribution parameter\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float, ndim=1)\n",
    "        The quadrature points\n",
    "    weights : np.ndarray(dtype=float, ndim=1)\n",
    "        The quadrature weights that correspond to nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``_qnwbeta1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    # We subtract one and write a + 1 where we actually want a, and a\n",
    "    # where we want a - 1\n",
    "    a = a - 1\n",
    "    b = b - 1\n",
    "\n",
    "    maxiter = 25\n",
    "\n",
    "    # Allocate empty space\n",
    "    nodes = np.zeros(n)\n",
    "    weights = np.zeros(n)\n",
    "\n",
    "    # Find \"reasonable\" starting values.  Why these numbers?\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            an = a/n\n",
    "            bn = b/n\n",
    "            r1 = (1+a) * (2.78/(4+n*n) + .768*an/n)\n",
    "            r2 = 1 + 1.48*an + .96*bn + .452*an*an + .83*an*bn\n",
    "            z = 1 - r1/r2\n",
    "        elif i == 1:\n",
    "            r1 = (4.1+a) / ((1+a)*(1+0.156*a))\n",
    "            r2 = 1 + 0.06 * (n-8) * (1+0.12*a)/n\n",
    "            r3 = 1 + 0.012*b * (1+0.25*abs(a))/n\n",
    "            z = z - (1-z) * r1 * r2 * r3\n",
    "        elif i == 2:\n",
    "            r1 = (1.67+0.28*a)/(1+0.37*a)\n",
    "            r2 = 1+0.22*(n-8)/n\n",
    "            r3 = 1+8*b/((6.28+b)*n*n)\n",
    "            z = z-(nodes[0]-z)*r1*r2*r3\n",
    "        elif i == n - 2:\n",
    "            r1 = (1+0.235*b)/(0.766+0.119*b)\n",
    "            r2 = 1/(1+0.639*(n-4)/(1+0.71*(n-4)))\n",
    "            r3 = 1/(1+20*a/((7.5+a)*n*n))\n",
    "            z = z+(z-nodes[-4])*r1*r2*r3\n",
    "        elif i == n - 1:\n",
    "            r1 = (1+0.37*b) / (1.67+0.28*b)\n",
    "            r2 = 1 / (1+0.22*(n-8)/n)\n",
    "            r3 = 1 / (1+8*a/((6.28+a)*n*n))\n",
    "            z = z+(z-nodes[-3])*r1*r2*r3\n",
    "        else:\n",
    "            z = 3*nodes[i-1] - 3*nodes[i-2] + nodes[i-3]\n",
    "\n",
    "        ab = a+b\n",
    "\n",
    "        # Root finding\n",
    "        its = 0\n",
    "        z1 = -100\n",
    "        while abs(z - z1) > 1e-10 and its < maxiter:\n",
    "            temp = 2 + ab\n",
    "            p1 = (a-b + temp*z)/2\n",
    "            p2 = 1\n",
    "\n",
    "            for j in range(2, n+1):\n",
    "                p3 = p2\n",
    "                p2 = p1\n",
    "                temp = 2*j + ab\n",
    "                aa = 2*j * (j+ab)*(temp-2)\n",
    "                bb = (temp-1) * (a*a - b*b + temp*(temp-2) * z)\n",
    "                c = 2 * (j - 1 + a) * (j - 1 + b) * temp\n",
    "                p1 = (bb*p2 - c*p3)/aa\n",
    "\n",
    "            pp = (n*(a-b-temp*z) * p1 + 2*(n+a)*(n+b)*p2)/(temp*(1 - z*z))\n",
    "            z1 = z\n",
    "            z = z1 - p1/pp\n",
    "\n",
    "            if abs(z - z1) < 1e-12:\n",
    "                break\n",
    "\n",
    "            its += 1\n",
    "\n",
    "        if its == maxiter:\n",
    "            raise ValueError(\"Max Iteration reached.  Failed to converge\")\n",
    "\n",
    "        nodes[i] = z\n",
    "        weights[i] = temp/(pp*p2)\n",
    "\n",
    "    nodes = (1-nodes)/2\n",
    "    weights = weights * math.exp(gammaln(a+n) + gammaln(b+n)\n",
    "                                 - gammaln(n+1) - gammaln(n+ab+1))\n",
    "    weights = weights / (2*math.exp(gammaln(a+1) + gammaln(b+1)\n",
    "                         - gammaln(ab+2)))\n",
    "\n",
    "    return nodes, weights\n",
    "\n",
    "\n",
    "def _qnwgamma1(n, a=None):\n",
    "    \"\"\"\n",
    "    Insert docs.  Default is a=0\n",
    "    NOTE: For now I am just following compecon; would be much better to\n",
    "    find a different way since I don't know what they are doing.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : scalar : int\n",
    "        The number of quadrature points\n",
    "    a : scalar : float\n",
    "        Gamma distribution parameter\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float, ndim=1)\n",
    "        The quadrature points\n",
    "    weights : np.ndarray(dtype=float, ndim=1)\n",
    "        The quadrature weights that correspond to nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwgamma1`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if a is None:\n",
    "        a = 0\n",
    "    else:\n",
    "        a -= 1\n",
    "\n",
    "    maxit = 10\n",
    "\n",
    "    factor = -math.exp(gammaln(a+n) - gammaln(n) - gammaln(a+1))\n",
    "    nodes = np.zeros(n)\n",
    "    weights = np.zeros(n)\n",
    "\n",
    "    # Create nodes\n",
    "    for i in range(n):\n",
    "        # Reasonable starting values\n",
    "        if i == 0:\n",
    "            z = (1+a) * (3+0.92*a) / (1 + 2.4*n + 1.8*a)\n",
    "        elif i == 1:\n",
    "            z = z + (15 + 6.25*a) / (1 + 0.9*a + 2.5*n)\n",
    "        else:\n",
    "            j = i-1\n",
    "            z = z + ((1 + 2.55*j) / (1.9*j) + 1.26*j*a / (1 + 3.5*j)) * \\\n",
    "                (z - nodes[j-1]) / (1 + 0.3*a)\n",
    "\n",
    "        # root finding iterations\n",
    "        its = 0\n",
    "        z1 = -10000\n",
    "        while abs(z - z1) > 1e-10 and its < maxit:\n",
    "            p1 = 1.0\n",
    "            p2 = 0.0\n",
    "            for j in range(1, n+1):\n",
    "                p3 = p2\n",
    "                p2 = p1\n",
    "                p1 = ((2*j - 1 + a - z)*p2 - (j - 1 + a)*p3) / j\n",
    "\n",
    "            pp = (n*p1 - (n+a)*p2) / z\n",
    "            z1 = z\n",
    "            z = z1 - p1/pp\n",
    "            its += 1\n",
    "\n",
    "        if its == maxit:\n",
    "            raise ValueError('Failure to converge')\n",
    "\n",
    "        nodes[i] = z\n",
    "        weights[i] = factor / (pp*n*p2)\n",
    "\n",
    "    return nodes, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwnorm(n, mu=None, sig2=None, usesqrtm=False):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for multivariate normal distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    mu : scalar or array_like(float), optional(default=zeros(d))\n",
    "        The means of each dimension of the random variable. If a scalar\n",
    "        is given, that constant is repeated d times, where d is the\n",
    "        number of dimensions\n",
    "    sig2 : array_like(float), optional(default=eye(d))\n",
    "        A d x d array representing the variance-covariance matrix of the\n",
    "        multivariate normal distribution.\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwnorm`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    n = np.asarray(n)\n",
    "    d = n.size\n",
    "\n",
    "    if mu is None:\n",
    "        mu = np.zeros(d)\n",
    "    else:\n",
    "        mu = np.asarray(mu)\n",
    "\n",
    "    if sig2 is None:\n",
    "        sig2 = np.eye(d)\n",
    "    else:\n",
    "        sig2 = np.asarray(sig2).reshape(d, d)\n",
    "\n",
    "    if all([x.size == 1 for x in [n, mu, sig2]]):\n",
    "        nodes, weights = _qnwnorm1(n)\n",
    "    else:\n",
    "        nodes = []\n",
    "        weights = []\n",
    "\n",
    "        for i in range(d):\n",
    "            _1d = _qnwnorm1(n[i])\n",
    "            nodes.append(_1d[0])\n",
    "            weights.append(_1d[1])\n",
    "\n",
    "        nodes = gridmake(*nodes)\n",
    "        weights = ckron(*weights[::-1])\n",
    "\n",
    "    if usesqrtm:\n",
    "        new_sig2 = la.sqrtm(sig2)\n",
    "    else:  # cholesky\n",
    "        new_sig2 = la.cholesky(sig2)\n",
    "\n",
    "    if d > 1:\n",
    "        nodes = nodes.dot(new_sig2) + mu  # Broadcast ok\n",
    "    else:  # nodes.dot(sig) will not be aligned in scalar case.\n",
    "        nodes = nodes * new_sig2 + mu\n",
    "\n",
    "    return nodes.squeeze(), weights\n",
    "\n",
    "\n",
    "def qnwlogn(n, mu=None, sig2=None):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for multivariate lognormal distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    mu : scalar or array_like(float), optional(default=zeros(d))\n",
    "        The means of each dimension of the random variable. If a scalar\n",
    "        is given, that constant is repeated d times, where d is the\n",
    "        number of dimensions\n",
    "    sig2 : array_like(float), optional(default=eye(d))\n",
    "        A d x d array representing the variance-covariance matrix of the\n",
    "        multivariate normal distribution.\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwlogn`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    nodes, weights = qnwnorm(n, mu, sig2)\n",
    "    return np.exp(nodes), weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def qnwunif(n, a, b):\n",
    "    \"\"\"\n",
    "    Computes quadrature nodes and weights for multivariate uniform\n",
    "    distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwunif`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    n, a, b = list(map(np.asarray, [n, a, b]))\n",
    "    nodes, weights = qnwlege(n, a, b)\n",
    "    weights = weights / np.prod(b - a)\n",
    "    return nodes, weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def quadrect(f, n, a, b, kind='lege', *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Integrate the d-dimensional function f on a rectangle with lower and\n",
    "    upper bound for dimension i defined by a[i] and b[i], respectively;\n",
    "    using n[i] points.\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        The function to integrate over. This should be a function\n",
    "        that accepts as its first argument a matrix representing points\n",
    "        along each dimension (each dimension is a column). Other\n",
    "        arguments that need to be passed to the function are caught by\n",
    "        `*args` and `**kwargs`\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    kind : string, optional(default='lege')\n",
    "        Specifies which type of integration to perform. Valid\n",
    "        values are:\n",
    "        lege - Gauss-Legendre\n",
    "        cheb - Gauss-Chebyshev\n",
    "        trap - trapezoid rule\n",
    "        simp - Simpson rule\n",
    "        N    - Neiderreiter equidistributed sequence\n",
    "        W    - Weyl equidistributed sequence\n",
    "        H    - Haber  equidistributed sequence\n",
    "        R    - Monte Carlo\n",
    "    *args, **kwargs :\n",
    "        Other arguments passed to the function f\n",
    "    Returns\n",
    "    -------\n",
    "    out : scalar (float)\n",
    "        The value of the integral on the region [a, b]\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``quadrect`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if kind.lower() == \"lege\":\n",
    "        nodes, weights = qnwlege(n, a, b)\n",
    "    elif kind.lower() == \"cheb\":\n",
    "        nodes, weights = qnwcheb(n, a, b)\n",
    "    elif kind.lower() == \"trap\":\n",
    "        nodes, weights = qnwtrap(n, a, b)\n",
    "    elif kind.lower() == \"simp\":\n",
    "        nodes, weights = qnwsimp(n, a, b)\n",
    "    else:\n",
    "        nodes, weights = qnwequi(n, a, b, kind)\n",
    "\n",
    "    out = weights.dot(f(nodes, *args, **kwargs))\n",
    "    return out\n",
    "\n",
    "\n",
    "def qnwbeta(n, a=1.0, b=1.0):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for beta distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float), optional(default=1.0)\n",
    "        A length-d\n",
    "    b : array_like(float), optional(default=1.0)\n",
    "        A d x d array representing the variance-covariance matrix of the\n",
    "        multivariate normal distribution.\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwbeta`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return _make_multidim_func(_qnwbeta1, n, a, b)\n",
    "\n",
    "\n",
    "def qnwgamma(n, a=None):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for gamma distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    mu : scalar or array_like(float), optional(default=zeros(d))\n",
    "        The means of each dimension of the random variable. If a scalar\n",
    "        is given, that constant is repeated d times, where d is the\n",
    "        number of dimensions\n",
    "    sig2 : array_like(float), optional(default=eye(d))\n",
    "        A d x d array representing the variance-covariance matrix of the\n",
    "        multivariate normal distribution.\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwgamma`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return _make_multidim_func(_qnwgamma1, n, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  For normal distribution\n",
    "\n",
    "x,w = qnwnorm(n,mu,var)\n",
    "where, mu is the mean and var is the variance\n",
    "\n",
    "-  For lognormal distribution\n",
    "\n",
    "x,w = qnwlogn(n,mu,var)\n",
    "\n",
    "where, mu is the log mean and var is the log variance\n",
    "\n",
    "-  For Beta distribution\n",
    "\n",
    "x,w = qnwbeta(n,a,b)\n",
    "\n",
    "where, a and b are the shape parameters \n",
    "\n",
    "-  For Gamma distribution\n",
    "\n",
    "x,w = qnwgamma(n,a,b) \n",
    "\n",
    "where, a is the shape parameter and b is the scale parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwlogn(n, mu=None, sig2=None):\n",
    "    \"\"\"\n",
    "    Computes nodes and weights for multivariate lognormal distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    mu : scalar or array_like(float), optional(default=zeros(d))\n",
    "        The means of each dimension of the random variable. If a scalar\n",
    "        is given, that constant is repeated d times, where d is the\n",
    "        number of dimensions\n",
    "    sig2 : array_like(float), optional(default=eye(d))\n",
    "        A d x d array representing the variance-covariance matrix of the\n",
    "        multivariate normal distribution.\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwlogn`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    nodes, weights = qnwnorm(n, mu, sig2)\n",
    "    return np.exp(nodes), weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To compute the agent’s expected utility with random income, execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Risk Problem\n",
    "1. An agent’s utility of income exhibits constant absolute risk aversion $\\alpha$ , viz.\n",
    "\n",
    "$$u(y) = -exp(- \\alpha  y)$$\n",
    "\n",
    "2. The agent faces uncertain income $\\tilde y$ that is log-normally distributed with parameters $\\mu$ and $\\sigma^2$\n",
    "\n",
    "3. Would this agent accept a certain income $y^∗$ in place of his uncertain income $\\tilde y$?\n",
    "\n",
    "4. According to expected utility theory, yes, provided \n",
    "\n",
    "$$u(y^∗) \\ge Eu(\\tilde y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "mu = 0\n",
    "var = 0.1\n",
    "alpha = 2\n",
    "ystar = 1\n",
    "y,w = qnwlogn(n,mu,var)\n",
    "expectedutility = -w@np.exp(-alpha*y)\n",
    "ucert = -np.exp(-alpha*ystar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectedutility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates the approximation $Eu(\\tilde y) = -0.148$\n",
    "which is less than $u(y^*) = -0.135$\n",
    "\n",
    "\n",
    "Yes, the agent would accept the certain income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility `qnwnorm` also generates discrete approximations for multivariate normal variates\n",
    "\n",
    "To generate mass points and probabilities for d jointly distributed normal random variables, execute the script\n",
    "\n",
    "`x,w = qnwnorm(n,mu,var)`\n",
    "\n",
    "\n",
    "where n is a 1×d vector indicating the number of mass points for each variable, mu is the 1×d mean vector, and var is the d× d covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On output, x is an N× d vector of mass points and w is an N× 1 vector of probabilities, where N= n 1⋅ n 2⋅… ⋅ n(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example\n",
    "\n",
    "A farmer’s per-acre revenue is the product of the unit price $\\tilde p$ and peracre yield $\\tilde y$, the logs of which are jointly normally distributed with the mean vector and covariance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([1, 2])\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = np.array([[0.2, -0.1], [-0.1, 0.4]])\n",
    "omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the farmer’s expected revenue using a grid of 150 mass points formed as the Cartesian product of 10 price nodes and 15 yield nodes, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,w = qnwnorm([10, 15],mu,omega)\n",
    "\n",
    "p = np.exp(x[:,0])\n",
    "\n",
    "y = np.exp(x[:,1])\n",
    "\n",
    "expectedrevenue = w@(p*y)\n",
    "\n",
    "expectedrevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As was the case with Newton-Cotes quadrature, tensor product principles may be used\n",
    "to generalize Gaussian quadrature rules to higher-dimensional integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: \n",
    "\n",
    "http://compeconworkshop.org/PDF/Part04.pdf\n",
    "\n",
    "https://people.ucsc.edu/~ealdrich/Teaching/ComputationGroup/Slides/lec3.pdf\n",
    "\n",
    "http://www.econ.nyu.edu/user/violante/NYUTeaching/QM/Spring15/Lectures/Lecture6_Integration_Slides.pdf\n",
    "\n",
    "https://github.com/birocoles/Disciplina-metodos-computacionais/blob/master/Content/newton-cotes.ipynb\n",
    "\n",
    "http://nbviewer.jupyter.org/github/sbustamante/ComputationalMethods/blob/master/material/numerical-calculus.ipynb#Numerical-Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Monte Carlo Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In numerical integration, methods such as the trapezoidal rule use a deterministic approach. Monte Carlo integration, on the other hand, employs a non-deterministic approach: each realization provides a different outcome.\n",
    "\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/20/MonteCarloIntegrationCircle.svg/440px-MonteCarloIntegrationCircle.svg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Monte Carlo integration methods are motivated by the **Strong Law of Large Numbers.**\n",
    "\n",
    "One version of the Law states that if $x_1; x_2; ... ; x_n$ are independent realizations of a random variable $\\tilde X$ and $f$ is a continuous function, then\n",
    "\n",
    "\n",
    "$$\\lim _{{n\\to \\infty }} \\frac{1}{n} \\sum_{i=1}^{n}  f(x_i) =  E f(\\tilde X)$$\n",
    "\n",
    "with probability one.\n",
    "\n",
    "The Monte Carlo integration scheme is thus a simple one. To compute an approximation to the expectation of $f(\\tilde X)$, one draws a random sample $x_1; x_2; ... ; x_n$ from the distribution of $\\tilde X$ and sets\n",
    "\n",
    "\n",
    "\n",
    "$$  E f(\\tilde X) \\approx \\frac{1}{n} \\sum_{i=1}^{n}  f(x_i) $$\n",
    "\n",
    "\n",
    "Monte Carlo integration uses uniform weights and “randomly” generated nodes\n",
    "\n",
    "**But could we draw a truly random sample?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Number Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Most numerical software packages provide a routine that generates pseudo-random variables\n",
    "that are uniformly distributed on the interval [0; 1]. A uniform random number generator\n",
    "is useful for generating random samples from other distributions. Suppose $\\tilde X$ has a cumulative distribution function  \n",
    "\n",
    "$$ F(x) = Pr( \\tilde X \\le x) $$\n",
    "\n",
    "\n",
    "whose inverse has a well-defined closed form. If $\\tilde U$ is uniformly distributed on $(0; 1)$, then\n",
    "$F^{-1}( \\tilde U)$ has the same distribution as $\\tilde X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most numerical software packages also provide an intrinsic routine that generates pseudorandom\n",
    "standard normal variables. The routine may also be used to generate pseudo-random sequences of lognormal and multivariate normal variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fundamental problem that arises with Monte Carlo integration is that it is almost impossible\n",
    "to generate a truly random sample of variates for any distribution. Most compilers\n",
    "and vector processing packages provide intrinsic routines for computing so-called random\n",
    "numbers. These routines, however, employ iteration rules that generate a purely deterministic,\n",
    "not random, sequence of numbers. In particular, if the generator is repeatedly initiated\n",
    "at the same point, it will return the same sequence of \"random\" variates each time. About\n",
    "all that can be said of numerical random number generators is that good ones will generate\n",
    "sequences that appear to be random, in that they pass certain statistical tests for randomness.\n",
    "For this reason, numerical random number generators are more accurately said to\n",
    "generate sequences of *\"pseudo-random\"* rather than random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python numpy offers two intrinsic random number generators \n",
    "\n",
    "- np.random.rand(m,n) generates an matrix of numbers that are independently uniformly distributed on the interval\n",
    "\n",
    "\n",
    "- np.random.randn(m,n) generates an matrix of numbers that are independently standard normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monte Carlo integration is easy to implement andmay be preferred over Gaussian quadrature\n",
    "if the a routine for computing the Gaussian mass points and probabilities is not readily\n",
    "available or if the integration is over many dimensions. Monte Carlo integration, however, is\n",
    "subject to a sampling error that cannot be bounded with certainty. The approximation can\n",
    "be made more accurate, in a dubious statistical sense, by increasing the size of the random\n",
    "sample, but this can be expensive if evaluating f or generating the pseudo-random variate is\n",
    "costly. Approximations generated by Monte Carlo integration will vary from one integration\n",
    "to the next, unless initiated at the same point, making the use of Monte Carlo integration\n",
    "in conjunction within other iterative schemes, such as dynamic programming or maximum\n",
    "likelihood estimation, problematic. So-called quasi Monte-Carlo methods can circumvent\n",
    "some of the problems associated with Monte-Carlo integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quasi-Monte Carlo uses a low-discrepancy sequence such as the Halton sequence, the Sobol sequence, or the Faure sequence, whereas Monte Carlo uses a pseudorandom sequence. The advantage of using low-discrepancy sequences is a faster rate of convergence. Quasi-Monte Carlo has a rate of convergence close to $O(1/N)$, whereas the rate for the Monte Carlo method is $O(N^{−0.5})$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Quasi-Monte Carlo method recently became popular in the area of mathematical finance or computational finance. In these areas, high-dimensional numerical integrals, where the integral should be evaluated within a threshold ε, occur frequently. Hence, the Monte Carlo method and the quasi-Monte Carlo method are beneficial in these situations.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Quasi-Monte_Carlo_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Quasi-Monte Carlo Integration\n",
    "\n",
    "\n",
    "Although Monte-Carlo integration methods originated using insights from probability\n",
    "theory, recent extensions have severed that connection and, in the process, demonstrated\n",
    "ways in which the methods can be improved. Monte-Carlo methods rely on\n",
    "sequences $x_i$ with the property that\n",
    "\n",
    "\n",
    "$$\\lim _{{n\\to \\infty }} \\frac{b-a}{n} \\sum_{i=1}^{n}  f(x_i) =  \\int_{a}^{b} f(x) dx$$\n",
    "\n",
    "\n",
    "without regard to whether the sequences passes standard tests of randomness. Any sequence\n",
    "that satisfies this condition for arbitrary (Riemann) integrable functions can be used to approximate an integral on [a; b]. Although the Law of Large Numbers assures us that this is true when the $x_i$ are independent and identically distributed random variables, other\n",
    "sequences also satisfy this property. Indeed, it can be shown that sequences that are explicitly\n",
    "non-random, but instead attempt to fill in space in a regular manner can often provide more\n",
    "accurate approximations to definite integrals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are numerous schemes for generating equidistributed sequences, including **the Neiderreiter,\n",
    "Weyl, and Haber sequences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the quadrature functions will use tensor products to generate nodes and\n",
    "weights for integration over an arbitrary bounded interval [a; b] in higher dimensional\n",
    "spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 An Integration Toolbox\n",
    "The Matlab toolbox accompanying the textbook includes four functions for computing\n",
    "numerical integrals for general functions. Each takes three inputs, n, a, and b and\n",
    "generates appropriate nodes and weights. The functions `qnwtrap` and `qnwsimp` implement the Newton-Cotes trapezoid and Simpson's rule methods, `qnwlege` implements\n",
    "Gauss-Legendre quadrature and `qnwequi` generates nodes and weights associated with\n",
    "either equidistributed or pseudo-random sequences. The calling syntax is the same\n",
    "for each and is illustrated with below with `qnwtrap`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwlege(n, a, b):\n",
    "    \"\"\"\n",
    "    Computes multivariate Guass-Legendre  quadrature nodes and weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int or array_like(float)\n",
    "        A length-d iterable of the number of nodes in each dimension\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwlege`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    return _make_multidim_func(_qnwlege1, n, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qnwequi(n, a, b, kind=\"N\", equidist_pp=None):\n",
    "    \"\"\"\n",
    "    Generates equidistributed sequences with property that averages\n",
    "    value of integrable function evaluated over the sequence converges\n",
    "    to the integral as n goes to infinity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of sequence points\n",
    "    a : scalar or array_like(float)\n",
    "        A length-d iterable of lower endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    b : scalar or array_like(float)\n",
    "        A length-d iterable of upper endpoints. If a scalar is given,\n",
    "        that constant is repeated d times, where d is the number of\n",
    "        dimensions\n",
    "    kind : string, optional(default=\"N\")\n",
    "        One of the following:\n",
    "        - N - Neiderreiter (default)\n",
    "        - W - Weyl\n",
    "        - H - Haber\n",
    "        - R - pseudo Random\n",
    "    equidist_pp : array_like, optional(default=None)\n",
    "        TODO: I don't know what this does\n",
    "    Returns\n",
    "    -------\n",
    "    nodes : np.ndarray(dtype=float)\n",
    "        Quadrature nodes\n",
    "    weights : np.ndarray(dtype=float)\n",
    "        Weights for quadrature nodes\n",
    "    Notes\n",
    "    -----\n",
    "    Based of original function ``qnwequi`` in CompEcon toolbox by\n",
    "    Miranda and Fackler\n",
    "    References\n",
    "    ----------\n",
    "    Miranda, Mario J, and Paul L Fackler. Applied Computational\n",
    "    Economics and Finance, MIT Press, 2002.\n",
    "    \"\"\"\n",
    "    if equidist_pp is None:\n",
    "        equidist_pp = np.sqrt(np.array(list(sym.primerange(0, 7920))))\n",
    "\n",
    "    n, a, b = list(map(np.atleast_1d, list(map(np.asarray, [n, a, b]))))\n",
    "\n",
    "    d = max(list(map(len, [n, a, b])))\n",
    "    n = np.prod(n)\n",
    "\n",
    "    if a.size == 1:\n",
    "        a = np.repeat(a, d)\n",
    "\n",
    "    if b.size == 1:\n",
    "        b = np.repeat(b, d)\n",
    "\n",
    "    i = np.arange(1, n + 1)\n",
    "\n",
    "    if kind.upper() == \"N\":  # Neiderreiter\n",
    "        j = 2.0 ** (np.arange(1, d+1) / (d+1))\n",
    "        nodes = np.outer(i, j)\n",
    "        nodes = (nodes - np.fix(nodes)).squeeze()\n",
    "    elif kind.upper() == \"W\":  # Weyl\n",
    "        j = equidist_pp[:d]\n",
    "        nodes = np.outer(i, j)\n",
    "        nodes = (nodes - np.fix(nodes)).squeeze()\n",
    "    elif kind.upper() == \"H\":  # Haber\n",
    "        j = equidist_pp[:d]\n",
    "        nodes = np.outer(i * (i+1) / 2, j)\n",
    "        nodes = (nodes - np.fix(nodes)).squeeze()\n",
    "    elif kind.upper() == \"R\":  # pseudo-random\n",
    "        nodes = np.random.rand(n, d).squeeze()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown sequence requested\")\n",
    "\n",
    "    # compute nodes and weights\n",
    "    r = b - a\n",
    "    nodes = a + nodes * r\n",
    "    weights = (np.prod(r) / n) * np.ones(n)\n",
    "\n",
    "    return nodes, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to compute the definite integral of $exp(x)$ on $[-1; 2]$ using a 10 point\n",
    "**trapezoid rule** one would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,w = qnwtrap(10,-1,2)\n",
    "print(x.shape, w.shape)\n",
    "integral = w.T@np.exp(x)\n",
    "integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To compute the definite integral using a 100 point **Neiderrieter rule** one would instead generate\n",
    "the nodes and weights as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,w] = qnwequi(100,-1,2,'N')\n",
    "print(x.shape, w.shape)\n",
    "integral = w.T@np.exp(x)\n",
    "integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each of the aforementioned routines also may be used to compute definite integrals of\n",
    "real-valued multivariate functions over bounded intervals in higher dimensional spaces. The\n",
    "routines generate nodes and weights for higher dimensional quadrature by forming the tensor\n",
    "products of univariate nodes and weights. For example, suppose one wished to compute the\n",
    "integral of $exp(x_1 + x_2)$ over the rectangle $[1, 2] \\times [0, 5]$ in $R^2$. One could call `qnwtrap` to\n",
    "construct a grid of, say, 300 quadrature nodes produced by taking the cross-product of 10\n",
    "nodes in the $x_1$ direction and 20 nodes in the $x_2$ direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,w] = qnwtrap([10, 20],[1, 0],[2, 5])\n",
    "print(x.shape, w.shape)\n",
    "integral = w.T@np.exp(x[:,0]+x[:,1])\n",
    "integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar calling syntax is used for qnwsimp, and qnwlege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calling syntax for qnwequi when performing multidimensional integration requires\n",
    "n to be an integer indicating the the total number of integration nodes. Thus, to compute\n",
    "the definite integral using a 10000 point **Neiderrieter rule** one would generate the nodes and\n",
    "weights as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,w] = qnwequi(10000,[1, 0],[2, 5],'N');\n",
    "print(x.shape, w.shape)\n",
    "integral = w.T@np.exp(x[:,0]+x[:,1]);\n",
    "integral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the general integration routines, there are\n",
    "several functions for computing Gaussian nodes and weights associated with common probability\n",
    "distribution functions. The routine qnwnorm generates the Gaussian quadrature nodes\n",
    "and weights for normal random variables. For univariate normal distributions, the calling\n",
    "syntax takes the form\n",
    "\n",
    "`[x,w] = qnwnorm(n,mu,var)`\n",
    "\n",
    "where x are the nodes, w are the probability weights, n is the number nodes and weights,\n",
    "mu the mean of the distribution, and var is the variance of the distribution. If mu and var\n",
    "are omitted, the mean and variance are assumed to be 0 and 1, respectively. For example,\n",
    "suppose one wanted to compute the expectation of $exp( \\tilde X)$ where $\\tilde X$\n",
    "is normally distributed\n",
    "with mean 2 and variance 4. An approximate expectation could be computed using the\n",
    "following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,w] = qnwnorm(3,2,4)\n",
    "print(x.shape,w.shape)\n",
    "expectation = w.T@np.exp(x)\n",
    "expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The routine qnwnorm also generates nodes and weights for multivariate normal random\n",
    "variables. For example, suppose one wished to compute the expectation of $exp( \\tilde X_1 + \\tilde X_2 )$\n",
    "where $\\tilde X$ and $\\tilde X$ are jointly normal with  $E \\tilde X_1  = 3 $, $E \\tilde X_2 = 4$, $V \\tilde X_1 = 2$, $V \\tilde X_2 = 4$, and $Cov( \\tilde X_1,\\tilde X_2) = -1 $.\n",
    "\n",
    "One could then invoke `qnwnorm` to construct a grid of 150 Gaussian quadrature nodes as the cross-product of 10 nodes in the $x_1$ direction and 15 nodes in the $x_2$ direction, and then form the weighted sum of the assigned weights and function values at the nodes:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,w] = qnwnorm([10, 15],[3, 4],[[2, -1], [-1, 4]])\n",
    "print(x.shape,w.shape)\n",
    "expectation = w.T@np.exp( x[:,0]+x[:,1] )\n",
    "expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Numerical Differentiation\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Derivative.svg/460px-Derivative.svg.png)\n",
    "\n",
    "\n",
    "The most natural way to approximate a derivative is to replace it with a finite difference.\n",
    "The definition of a derivative,\n",
    "\n",
    "$$ f'(x)=\\lim _{{h\\to 0}}{f(x+h)-f(x) \\over h}. $$\n",
    "\n",
    "suggests a natural way to do this. One can simply take h to be a small number, knowing\n",
    "that, for h small enough, the error of the approximation will also be small. We will return\n",
    "to the question of how small h should be, but first we address the issue of how large an error\n",
    "is produced using this finite difference approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error bound for the approximation can be be obtained using a Taylor expansion. We\n",
    "know, for example, that\n",
    "$$f(x + h) = f(x) + f'(x)h + O(h^2);$$\n",
    "\n",
    "where $O(h^2)$ means that other terms in the expression are expressible in terms of second or\n",
    "higher powers of h. If we rearrange this expression we see that\n",
    "\n",
    "$$f'(x) = [f(x + h) - f(x)]/h + O(h)$$\n",
    "\n",
    "(since $O(h^2)/h = O(h)$), so the approximation to the derivative $f'(x)$ has an $O(h)$ error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more accurate finite difference approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "Another two-point formula is to compute the slope of a nearby secant line through the points $(x-h,f(x-h))$ and $(x+h,f(x+h))$. The slope of this line is\n",
    "$$f'(x) =    {\\displaystyle {f(x+h)-f(x-h) \\over 2h } + O(h^2) .} $$\n",
    "This formula is known as the symmetric difference quotient. In this case the first-order errors cancel, so the slope of these secant lines differ from the slope of the tangent line by an amount that is approximately proportional to ${\\displaystyle h^{2}}$. Hence for small values of h this is a more accurate approximation to the tangent line than the one-sided estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is called the **centered finite difference approximation** to the derivative of $f$ at $x$. Its\n",
    "error is $O(h^2)$, or one order more accurate than the one-sided finite difference approximation\n",
    "above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Other 3-point approximations are also possible.\n",
    "\n",
    "### A special case the approximation in the centered finite difference approximation\n",
    "\n",
    "a formula that is useful when a derivative is needed at a boundary of a domain. In this case\n",
    "\n",
    "$$f'(x) = {1 \\over 2h} [-3f(x) + 4f(x + h) - f(x + 2h)] + O(h^2)$$\n",
    "(use h > 0 for a lower bound and h < 0 for an upper bound).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finite difference approximations** for higher order derivatives \n",
    "\n",
    "can be found using a similar\n",
    "approach. For, example an order $O(h^2)$ centered finite difference approximation to the second\n",
    "derivative may be constructed using the two third-order Taylor expansions\n",
    "\n",
    "$$f''(x) = {f(x + h) - 2f(x) + f(x - h) \\over h^2} + O(h^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain general formulii for second derivatives with second order accuracy,\n",
    "\n",
    "a formula that is useful when a derivative is needed at a boundary of the\n",
    "domain. In this case\n",
    "\n",
    "\n",
    "$$f''(x) ={1 \\over h^2} [2f(x) - 5f(x + h) + 4f(x + 2h) - f(x + 3h)] + O(h^2)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing Hessian matrices\n",
    "\n",
    "\n",
    "An important use of second derivatives is in computing Hessian matrices. Given some\n",
    "function $f : R^n \\rightarrow R$, the Hessian is the $n \\times n$ matrix of second partial derivatives, the $ij$th element of which is ${ \\partial^2 f(x)\\over  \\partial x_i \\partial x_j}$\n",
    ". We consider only centered, evenly spaced approximations, which\n",
    "can be obtained as a weighted sum of the function values evaluated at the point x and 8\n",
    "points surrounding it obtained by adding or subtracting $h_i u_i$ and/or $h_j u_j$, where the h terms\n",
    "are scalar step increments and the u terms are n-vectors of zeros but with the ith element\n",
    "equal to 1 (the $i$th column of $I_n$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and let superscripts on f denote the function evaluated at one\n",
    "of the 9 points of interest, so $f^{++} = f(x + h_i u_i + h_j u_j)$, $f^{00} = f(x), f^{0-} = f(x - h_j u_j)$, etc.\n",
    "\n",
    "\n",
    "The obvious combination of taking the mean of the two results in\n",
    "\n",
    "$$f_{ij} \\approx {1 \\over 4h_i h_j} (f^{++} + f^{--} - f^{-+} -  f^{+-})$$\n",
    "\n",
    "This requires less computation than the other two forms if only a single cross partial is\n",
    "evaluated. Using either of the other two schemes, however, along with the usual centered\n",
    "approximation for the diagonal terms of the Hessian enables one to compute the entire\n",
    "Hessian with second order accuracy in $1 + n + n^2$ function evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the errors in approximating\n",
    "When a function can be evaluated at any point, the choice of evaluation points must be\n",
    "considered. As with convergence criteria, there is no one rule that always works. If **$h$ is\n",
    "made too small, round-off error can make the results meaningless**. On the other hand, too\n",
    "large an h provides a poor approximation, even if exact arithmetic is used.\n",
    "\n",
    "This gives credence to the rule of\n",
    "thumb that, for one-sided approximations, h should be chosen to be of size $\\epsilon$ relative to\n",
    "x. When x is small, however, it is better not to let h get too small. We suggest the rule of\n",
    "thumb of setting \n",
    "\n",
    "$$h = max(x, 1) \\sqrt{ \\epsilon} $$\n",
    "\n",
    "\n",
    "It is evident that the\n",
    "error is minimized at a much higher value of h, at approximately $\\sqrt[3]{\\epsilon}$. A good rule of thumb\n",
    "is to set\n",
    "\n",
    "$$h = max(x, 1) \\sqrt[3]{ \\epsilon} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide below a function that computes two-sided finite difference approximations for\n",
    "the Jacobian of an arbitrary function. For a real-valued function, $f :R^n \\rightarrow R$, the output\n",
    "is an $m \\times n$ matrix:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fdjac(func, x, *args, **kwargs):\n",
    "\n",
    "    # if type(func(x, *args, **kwargs)) is tuple:\n",
    "    #     F = lambda x: func(x, *args, **kwargs)[0]\n",
    "    # else:\n",
    "    #     F = lambda x: func(x, *args, **kwargs)\n",
    "    F = lambda z: func(z, *args, **kwargs)\n",
    "\n",
    "    x = x.flatten()\n",
    "    dx = x.size\n",
    "    f = F(x)\n",
    "    df = f.size\n",
    "    x = x.astype(float)\n",
    "\n",
    "    ''' Compute Jacobian'''\n",
    "    eps = np.spacing(1) \n",
    "\n",
    "    h = eps** (1/3) * np.maximum(abs(x), 1)\n",
    "    xh0 = x - h\n",
    "    xh1 = x + h\n",
    "    h = xh1 - xh0\n",
    "    fjac = np.zeros((dx, df))\n",
    "\n",
    "    for j in range(dx):\n",
    "        xx = x.copy()\n",
    "        xx[j] = xh1[j]\n",
    "        f1 = F(xx)\n",
    "\n",
    "        xx[j] = xh0[j]\n",
    "        f0 = F(xx)\n",
    "\n",
    "        fjac[j] = np.squeeze((f1 - f0) / h[j])  # fixme doing this to deal with broadcasting\n",
    "\n",
    "    return fjac.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "def cournot(q):\n",
    "    c = np.array([0.6, 0.8])\n",
    "    eta = 1.6\n",
    "    e = -1 / eta\n",
    "    fval = np.sum(q)**e + e * np.sum(q)**(e-1)*(q) - np.diag(c).dot(q)\n",
    "    return fval\n",
    "\n",
    "f = cournot\n",
    "x = np.array([0.2, 0.2])\n",
    "# using numerical finite difference function to calculate Jacobian\n",
    "fjac = fdjac(cournot,np.array([0.2, 0.2]) )\n",
    "fjac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Initial Value Problems\n",
    "Differential equations pose the problem of inferring a function given information\n",
    "about its derivatives and additional \"boundary\" conditions. Differential equations\n",
    "may characterized as either **ordinary differential equations (ODEs)**, whose solutions\n",
    "are functions of a single argument, and **partial differential equations (PDEs)**, whose\n",
    "solutions are functions of multiple arguments. Both ODEs and PDEs may be solved\n",
    "numerically using finite difference methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a numerical point of view the distinction between ODEs and PDEs is less\n",
    "important than the distinction between **initial value problems (IVPs)**, which can be\n",
    "solved in a recursive or evolutionary fashion, and **boundary value problems (BVPs)**,\n",
    "which require the entire solution to be computed simultaneously because the solution\n",
    "at one point (in time and/or space) depends on the solution everywhere else. For\n",
    "ODEs, the solution of an IVP is known at some point and the solution near this\n",
    "point can then be (approximately) determined. This, in turn, allows the solution at\n",
    "still other points to be approximated and so forth. BVPs, on the other hand, require\n",
    "simultaneous solution of the differential equation and the boundary conditions. We\n",
    "take up the solution of IVPs in this section, but defer discussion of BVPs until the\n",
    "next chapter (page 164)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most common initial value problem is to find a function $x : [0, T] \\rightarrow R^2$ whose initial\n",
    "value $x(0)$ is known and which, over its domain, satisfies the differential equation\n",
    "\n",
    "$$x'(t) = f(t,x(t)).$$\n",
    "\n",
    "\n",
    "Here, $x$ is a function of a scalar $t$ (often referring to time in economic applications) and\n",
    "$f : [0, T] \\times R^2 \\rightarrow R^2$ is a given function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Initial value problems can be solved using a recursive procedure. First the direction of\n",
    "motion is calculated based on the current position of the system and a small step is taken\n",
    "in that direction. This is then repeated as many times as is desired. The inputs needed for these methods are the functions defining the system $f$, an initial value $x_0$, the time step size\n",
    "h, and the number of steps to take n (or, equivalently, the stopping point T)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euler's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple form of such a procedure is **Euler's method**. The ith iteration of the\n",
    "procedure generates an approximation for the value of the solution function $x$ at time $t_i$\n",
    "\n",
    "\n",
    "$$x_{i+1} = x_i + hf(t_i, x_i),$$\n",
    "\n",
    "with the procedure beginning at the prescribed $x_0 = x(0)$. This method is fine for rough\n",
    "approximations, especially if the time step is small enough. Higher order approximations\n",
    "can yield better results, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1\n",
    "# Solve y'(t)=-2y(t) with y0=3\n",
    "y0 = 3;                  # Initial Condition\n",
    "h = 0.2;# Time step\n",
    "t = np.arange(0,2 ,h)                # t goes from 0 to 2 seconds.\n",
    "yexact = 3*np.exp(-2*t)     # Exact solution (in general we won't know this)\n",
    "ystar = np.zeros(len(t))  # Preallocate array (good coding practice)\n",
    "\n",
    "ystar[0] = y0           # Initial condition gives solution at t=0.\n",
    "for i in range(len(t)-1):\n",
    "    k1 = -2*ystar[i];  # Previous approx for y gives approx for derivative\n",
    "    ystar[i+1] = ystar[i] + k1*h # Approximate solution for next value of y\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t,yexact,'k--', label = 'Exact' )\n",
    "ax.plot(t,ystar,':',label = 'Approximate' )\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runge-Kutta method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the numerous refinements on the Euler method, the most commonly used are the\n",
    "Runge-Kutta methods. Runge-Kutta methods are a class of methods characterized by an\n",
    "order of approximation and by selection of certain key parameters. The derivation of these\n",
    "methods is fairly tedious for high order methods but are easily demonstrated for a second\n",
    "order model.\n",
    "\n",
    "Reference:\n",
    "https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following second order Runge-Kutta methods:\n",
    "\n",
    "Let an initial value problem be specified as follows:\n",
    "$${\\displaystyle {\\dot {y}}=f(t,y),\\quad y(t_{0})=y_{0}.}$$\n",
    "\n",
    "$$y_{n+1}=y_{n}+h{\\bigl (}(1-{\\tfrac {1}{2\\alpha }})f(t_{n},y_{n})+{\\tfrac {1}{2\\alpha }}f(t_{n}+\\alpha h,y_{n}+\\alpha hf(t_{n},y_{n})){\\bigr )} + O(h^3).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be shown that an optimal choice, in the sense of minimizing the absolute value of the\n",
    "$h^3$ term in the truncation error, is to set $ \\alpha= 2/3$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most widely used Runge-Kutta method is the **classical fourth-order method**. A\n",
    "derivation of this approach is tedious but the algorithm is straightforward:\n",
    "\n",
    "The most widely known member of the Runge–Kutta family is generally referred to as \"RK4\", \"classical Runge–Kutta method\" or simply as \"the Runge–Kutta method\".\n",
    "\n",
    "\n",
    "\n",
    "$${\\displaystyle {\\begin{aligned}y_{n+1}&=y_{n}+{\\tfrac {h}{6}}\\left(k_{1}+2k_{2}+2k_{3}+k_{4}\\right),\\\\t_{n+1}&=t_{n}+h\\\\\\end{aligned}}}$$\n",
    "\n",
    "\n",
    "for n = 0, 1, 2, 3, ..., using\n",
    "\n",
    "$${\\displaystyle {\\begin{aligned}k_{1}&=f(t_{n},y_{n}),\\\\k_{2}&=h f\\left(t_{n}+{\\frac {h}{2}},y_{n}+{\\frac {1}{2}}k_{1}\\right),\\\\k_{3}&=h f\\left(t_{n}+{\\frac {h}{2}},y_{n}+{\\frac {1}{2}}k_{2}\\right),\\\\k_{4}&=h f\\left(t_{n}+h,y_{n}+k_{3}\\right).\\end{aligned}}} $$\n",
    "\n",
    "(Note: the above equations have different but equivalent definitions in different texts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Example:\n",
    "\n",
    "using the Runge-Kutta 4th order method on a system of 2 first order ODE's.\n",
    "\n",
    "https://math.stackexchange.com/questions/721076/help-with-using-the-runge-kutta-4th-order-method-on-a-system-of-2-first-order-od\n",
    "\n",
    "\n",
    "The original ODE\n",
    "\n",
    "$$\\frac{d^2y}{dx^2}+\\frac{dy}{dx}-6y=0$$\n",
    "\n",
    "with $y(0)=3$ and $y'(0)=1$.\n",
    "\n",
    "Substitute $z = y'$\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "  \\frac{dy}{dx} = z \\\\\n",
    "  \\frac{dz}{dx} = 6y - z\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "With y(0)=3 and z(0)=1.\n",
    "\n",
    "In python, index starts form 0.\n",
    "\n",
    "$$k_0 = hf(x_i,y_i,z_i)$$\n",
    "\n",
    "$$l_0 = hg(x_i,y_i,z_i)$$\n",
    "\n",
    "$$k_1 = hf(x_i+\\frac{1}{2}h,y_i+\\frac{1}{2}k_0,z_i+\\frac{1}{2}l_0)$$\n",
    "\n",
    "$$l_1 = hg(x_i+\\frac{1}{2}h,y_i+\\frac{1}{2}k_0,z_i+\\frac{1}{2}l_0)$$\n",
    "\n",
    "$$k_2 = hf(x_i+\\frac{1}{2}h,y_i+\\frac{1}{2}k_1,z_i+\\frac{1}{2}l_1)$$\n",
    "\n",
    "$$l_2 = hg(x_i+\\frac{1}{2}h,y_i+\\frac{1}{2}k_2,z_i+\\frac{1}{2}l_1)$$\n",
    "\n",
    "$$k_3 = hf(x_i+h,y_i+k_2,z_i+l_2)$$\n",
    "\n",
    "$$l_3 = hg(x_i+h,y_i+k_2,z_i+l_2)$$\n",
    "\n",
    "$$y_{i+1}=y_i + \\frac{1}{6}(k_0+2k_1+2k_2+k_3)$$\n",
    "\n",
    "$$z_{i+1}=z_i + \\frac{1}{6}(l_0+2l_1+2l_2+l_3)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A Matlab implementation is given below:\n",
    "\n",
    "```matlab\n",
    "% It calculates ODE using Runge-Kutta 4th order method\n",
    "% Author Ido Schwartz\n",
    "% Originally available form: http://www.mathworks.com/matlabcentral/fileexchange/29851-runge-kutta-4th-order-ode/content/Runge_Kutta_4.m\n",
    "% Edited by Amin A. Mohammed, for 2 ODEs(April 2016)\n",
    "\n",
    "clc;                                               % Clears the screen\n",
    "clear all;\n",
    "\n",
    "h=0.1;                                             % step size\n",
    "x = 0:h:1;                                         % Calculates upto y(1)\n",
    "y = zeros(1,length(x)); \n",
    "z = zeros(1,length(x)); \n",
    "y(1) = 3;                                          % initial condition\n",
    "z(1) = 1;                                          % initial condition\n",
    "% F_xy = @(t,r) 3.*exp(-t)-0.4*r;                  % change the function as you desire\n",
    "F_xyz = @(x,y,z) z;                                  % change the function as you desire\n",
    "G_xyz = @(x,y,z) 6*y-z;\n",
    "\n",
    "for i=1:(length(x)-1)                              % calculation loop\n",
    "    k_1 = F_xyz(x(i),y(i),z(i));\n",
    "    L_1 = G_xyz(x(i),y(i),z(i));\n",
    "    k_2 = F_xyz(x(i)+0.5*h,y(i)+0.5*h*k_1,z(i)+0.5*h*L_1);\n",
    "    L_2 = G_xyz(x(i)+0.5*h,y(i)+0.5*h*k_1,z(i)+0.5*h*L_1);\n",
    "    k_3 = F_xyz((x(i)+0.5*h),(y(i)+0.5*h*k_2),(z(i)+0.5*h*L_2));\n",
    "    L_3 = G_xyz((x(i)+0.5*h),(y(i)+0.5*h*k_2),(z(i)+0.5*h*L_2));\n",
    "    k_4 = F_xyz((x(i)+h),(y(i)+k_3*h),(z(i)+L_3*h)); % Corrected        \n",
    "    L_4 = G_xyz((x(i)+h),(y(i)+k_3*h),(z(i)+L_3*h));\n",
    "\n",
    "    y(i+1) = y(i) + (1/6)*(k_1+2*k_2+2*k_3+k_4)*h;  % main equation\n",
    "    z(i+1) = z(i) + (1/6)*(L_1+2*L_2+2*L_3+L_4)*h;  % main equation\n",
    "\n",
    "end\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the question in $t$ with variables $y= [x, z]$\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "  \\frac{dx}{dt} = z \\\\\n",
    "  \\frac{dz}{dt} = 6x - z\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "With x(0)=3 and z(0)=1.\n",
    "\n",
    "We can vectorize the implementation in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34965829/runge-kuttas-method-circular-motion/34967062#34967062\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def rk4(f,t0,y0,tn,h):\n",
    "    '''Classical RK4 with fixed step size, modify h to fit\n",
    "        the full interval\n",
    "        y: vector of variables [x, z]\n",
    "        f: differential equation\n",
    "        \n",
    "        t0： initial t\n",
    "        y0: initial y\n",
    "        tn: n\n",
    "        h: step size\n",
    "        '''\n",
    "    N = np.ceil( (tn-t0)/h )\n",
    "    h = (tn-t0)/N\n",
    "\n",
    "    t = t0\n",
    "    y = np.array(y0)\n",
    "    for k in range(int(N)):\n",
    "        k1 = h*np.array(f(t      ,y       ))\n",
    "        k2 = h*np.array(f(t+0.5*h,y+0.5*k1))\n",
    "        k3 = h*np.array(f(t+0.5*h,y+0.5*k2))\n",
    "        k4 = h*np.array(f(t+    h,y+    k3))\n",
    "        y = y + (k1+2*(k2+k3)+k4)/6\n",
    "        t = t + h\n",
    "    return t, y\n",
    "\n",
    "def odefunc(t,y):\n",
    "    x,z = y         # \n",
    "    return [ z,6*x-z ]\n",
    "\n",
    "\n",
    "print(rk4(odefunc, 0, [3,1], 1, 0.1)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue this for 10 time steps. Your final result should match closely (assuming the numerical algorithm is stable for this problem) to the exact solution. \n",
    "\n",
    "\n",
    "You will compare $z_{10}$ to the exact result. The exact solution is:\n",
    "\n",
    "\n",
    "$$x(t) = e^{-3 t}+2 e^{2 t}$$\n",
    "\n",
    "\n",
    "If we find\n",
    "\n",
    "\n",
    "$$x(1) = \\dfrac{1}{e^3} + 2 e^2 = 14.8278992662291643974401973...$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous other approaches and refinements to solving initial value problems.\n",
    "Brie\n",
    "y, these include so-called multi-step algorithms which utilize information\n",
    "from previous steps to determine the current step direction (Runge-Kutta are singlestep\n",
    "methods). Also, any method can adapt the step size to the current behavior\n",
    "of the system by monitoring the truncation error, reducing (increasing) the step size\n",
    "if this error is unacceptably large (small). Adaptive schemes are important if one\n",
    "requires a given level of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Commercial Fishery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fdif03(t,x):\n",
    "    s,k=x\n",
    "    beta = 2.75\n",
    "    f = 0.06\n",
    "    delta = 10 \n",
    "    temp=1 + beta*s*k\n",
    "    ds=(1-s)*s-s*k/temp;\n",
    "    dk=delta*(s/(temp**2)-2*f);\n",
    "    return [ds,dk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rk4(fdif03, 0, [0.5,1], 1, 0.1)) # 10 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rk4(fdif03, 0, [0.5,1], 10, 0.1)) # 100 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rk4(fdif03, 0, [0.1,1], 10, 0.1)) # 100 steps converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rk4(fdif03, 0, [0.5,1.6], 100, 0.1)) # 1000 steps converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rk4(fdif03, 0, [0.5,1.6], 1000, 0.1)) # 10000 steps converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Scipy Integrate package:\n",
    "\n",
    "If we are looking for an algorithm to integrate a function in python, we might explore the integrate package:\n",
    "\n",
    "```python\n",
    "import scipy.integrate\n",
    "\n",
    "scipy.integrate?\n",
    "```\n",
    "produces:\n",
    "\n",
    "```\n",
    "=============================================\n",
    "Integration and ODEs (:mod:`scipy.integrate`)\n",
    "=============================================\n",
    "\n",
    ".. currentmodule:: scipy.integrate\n",
    "\n",
    "Integrating functions, given function object\n",
    "============================================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   quad          -- General purpose integration\n",
    "   dblquad       -- General purpose double integration\n",
    "   tplquad       -- General purpose triple integration\n",
    "   nquad         -- General purpose n-dimensional integration\n",
    "   fixed_quad    -- Integrate func(x) using Gaussian quadrature of order n\n",
    "   quadrature    -- Integrate with given tolerance using Gaussian quadrature\n",
    "   romberg       -- Integrate func using Romberg integration\n",
    "   quad_explain  -- Print information for use of quad\n",
    "   newton_cotes  -- Weights and error coefficient for Newton-Cotes integration\n",
    "   IntegrationWarning -- Warning on issues during integration\n",
    "\n",
    "Integrating functions, given fixed samples\n",
    "==========================================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   trapz         -- Use trapezoidal rule to compute integral.\n",
    "   cumtrapz      -- Use trapezoidal rule to cumulatively compute integral.\n",
    "   simps         -- Use Simpson's rule to compute integral from samples.\n",
    "   romb          -- Use Romberg Integration to compute integral from\n",
    "                 -- (2**k + 1) evenly-spaced samples.\n",
    "\n",
    ".. seealso::\n",
    "\n",
    "   :mod:`scipy.special` for orthogonal polynomials (special) for Gaussian\n",
    "   quadrature roots and weights for other weighting factors and regions.\n",
    "\n",
    "Integrators of ODE systems\n",
    "==========================\n",
    "\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "\n",
    "   odeint        -- General integration of ordinary differential equations.\n",
    "   ode           -- Integrate ODE using VODE and ZVODE routines.\n",
    "   complex_ode   -- Convert a complex-valued ODE to real-valued and integrate.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: integrate\n",
    "\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# function we want to integrate\n",
    "def f(x):\n",
    "    return np.exp(np.cos(-2 * x * np.pi)) + 3.2\n",
    "\n",
    "# call quad to integrate f from -2 to 2\n",
    "res, err = quad(f, -2, 2)\n",
    "\n",
    "print(\"The numerical result is {:f} (+-{:g})\"\n",
    "    .format(res, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `quad()` takes optional parameters `epsabs` and `epsrel` to increase or decrease the accuracy of its computation. (Use `help(quad)` to learn more.) The default values are `epsabs=1.5e-8` and `epsrel=1.5e-8`. For the next exercise, the default values are sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: solve ode\n",
    "\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "\n",
    "def f(y, t):\n",
    "    \"\"\"this is the rhs of the ODE to integrate, i.e. dy/dt=f(y,t)\"\"\"\n",
    "    return -2 * y * t\n",
    "\n",
    "y0 = 1             # initial value\n",
    "a = 0              # integration limits for t\n",
    "b = 2\n",
    "\n",
    "t = np.arange(a, b, 0.01)  # values of t for\n",
    "                          # which we require\n",
    "                          # the solution y(t)\n",
    "y = odeint(f, y0, t)  # actual computation of y(t)\n",
    "\n",
    "# plotting of results\n",
    "plt.figure();\n",
    "plt.plot(t, y);\n",
    "plt.xlabel('t'); plt.ylabel('y(t)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `odein`t command takes a number of optional parameters to change the default error tolerance of the integration (and to trigger the production of extra debugging output). Use the help command to explore these:\n",
    "\n",
    "```\n",
    "help(scipy.integrate.odeint)\n",
    "```\n",
    "will show:\n",
    "\n",
    "```\n",
    "Help on function odeint in module scipy.integrate.odepack:\n",
    "\n",
    "odeint(func, y0, t, args=(), Dfun=None, col_deriv=0, full_output=0, ml=None, mu=None, rtol=None, atol=None, tcrit=None, h0=0.0, hmax=0.0, hmin=0.0, ixpr=0, mxstep=0, mxhnil=0, mxordn=12, mxords=5, printmessg=0)\n",
    "    Integrate a system of ordinary differential equations.\n",
    "\n",
    "    Solve a system of ordinary differential equations using lsoda from the\n",
    "    FORTRAN library odepack.\n",
    "\n",
    "    Solves the initial value problem for stiff or non-stiff systems\n",
    "    of first order ode-s::\n",
    "\n",
    "        dy/dt = func(y, t0, ...)\n",
    "\n",
    "    where y can be a vector.\n",
    "\n",
    "    *Note*: The first two arguments of ``func(y, t0, ...)`` are in the\n",
    "    opposite order of the arguments in the system definition function used\n",
    "    by the `scipy.integrate.ode` class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable(y, t0, ...)\n",
    "        Computes the derivative of y at t0.\n",
    "    y0 : array\n",
    "        Initial condition on y (can be a vector).\n",
    "    t : array\n",
    "        A sequence of time points for which to solve for y.  The initial\n",
    "        value point should be the first element of this sequence.\n",
    "    args : tuple, optional\n",
    "        Extra arguments to pass to function.\n",
    "    Dfun : callable(y, t0, ...)\n",
    "        Gradient (Jacobian) of `func`.\n",
    "    col_deriv : bool, optional\n",
    "        True if `Dfun` defines derivatives down columns (faster),\n",
    "        otherwise `Dfun` should define derivatives across rows.\n",
    "    full_output : bool, optional\n",
    "        True if to return a dictionary of optional outputs as the second output\n",
    "    printmessg : bool, optional\n",
    "        Whether to print the convergence message\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array, shape (len(t), len(y0))\n",
    "        Array containing the value of y for each desired time in t,\n",
    "        with the initial value `y0` in the first row.\n",
    "    infodict : dict, only returned if full_output == True\n",
    "        Dictionary containing additional output information\n",
    "\n",
    "        =======  ============================================================\n",
    "        key      meaning\n",
    "        =======  ============================================================\n",
    "        'hu'     vector of step sizes successfully used for each time step.\n",
    "        'tcur'   vector with the value of t reached for each time step.\n",
    "                 (will always be at least as large as the input times).\n",
    "        'tolsf'  vector of tolerance scale factors, greater than 1.0,\n",
    "                 computed when a request for too much accuracy was detected.\n",
    "        'tsw'    value of t at the time of the last method switch\n",
    "                 (given for each time step)\n",
    "        'nst'    cumulative number of time steps\n",
    "        'nfe'    cumulative number of function evaluations for each time step\n",
    "        'nje'    cumulative number of jacobian evaluations for each time step\n",
    "        'nqu'    a vector of method orders for each successful step.\n",
    "        'imxer'  index of the component of largest magnitude in the\n",
    "                 weighted local error vector (e / ewt) on an error return, -1\n",
    "                 otherwise.\n",
    "        'lenrw'  the length of the double work array required.\n",
    "        'leniw'  the length of integer work array required.\n",
    "        'mused'  a vector of method indicators for each successful time step:\n",
    "                 1: adams (nonstiff), 2: bdf (stiff)\n",
    "        =======  ============================================================\n",
    "\n",
    "    Other Parameters\n",
    "    ----------------\n",
    "    ml, mu : int, optional\n",
    "        If either of these are not None or non-negative, then the\n",
    "        Jacobian is assumed to be banded.  These give the number of\n",
    "        lower and upper non-zero diagonals in this banded matrix.\n",
    "        For the banded case, `Dfun` should return a matrix whose\n",
    "        rows contain the non-zero bands (starting with the lowest diagonal).\n",
    "        Thus, the return matrix `jac` from `Dfun` should have shape\n",
    "        ``(ml + mu + 1, len(y0))`` when ``ml >=0`` or ``mu >=0``.\n",
    "        The data in `jac` must be stored such that ``jac[i - j + mu, j]``\n",
    "        holds the derivative of the `i`th equation with respect to the `j`th\n",
    "        state variable.  If `col_deriv` is True, the transpose of this\n",
    "        `jac` must be returned.\n",
    "    rtol, atol : float, optional\n",
    "        The input parameters `rtol` and `atol` determine the error\n",
    "        control performed by the solver.  The solver will control the\n",
    "        vector, e, of estimated local errors in y, according to an\n",
    "        inequality of the form ``max-norm of (e / ewt) <= 1``,\n",
    "        where ewt is a vector of positive error weights computed as\n",
    "        ``ewt = rtol * abs(y) + atol``.\n",
    "        rtol and atol can be either vectors the same length as y or scalars.\n",
    "        Defaults to 1.49012e-8.\n",
    "    tcrit : ndarray, optional\n",
    "        Vector of critical points (e.g. singularities) where integration\n",
    "        care should be taken.\n",
    "    h0 : float, (0: solver-determined), optional\n",
    "        The step size to be attempted on the first step.\n",
    "    hmax : float, (0: solver-determined), optional\n",
    "        The maximum absolute step size allowed.\n",
    "    hmin : float, (0: solver-determined), optional\n",
    "        The minimum absolute step size allowed.\n",
    "    ixpr : bool, optional\n",
    "        Whether to generate extra printing at method switches.\n",
    "    mxstep : int, (0: solver-determined), optional\n",
    "        Maximum number of (internally defined) steps allowed for each\n",
    "        integration point in t.\n",
    "    mxhnil : int, (0: solver-determined), optional\n",
    "        Maximum number of messages printed.\n",
    "    mxordn : int, (0: solver-determined), optional\n",
    "        Maximum order to be allowed for the non-stiff (Adams) method.\n",
    "    mxords : int, (0: solver-determined), optional\n",
    "        Maximum order to be allowed for the stiff (BDF) method.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    ode : a more object-oriented integrator based on VODE.\n",
    "    quad : for finding the area under a curve.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    The second order differential equation for the angle `theta` of a\n",
    "    pendulum acted on by gravity with friction can be written::\n",
    "\n",
    "        theta''(t) + b*theta'(t) + c*sin(theta(t)) = 0\n",
    "\n",
    "    where `b` and `c` are positive constants, and a prime (') denotes a\n",
    "    derivative.  To solve this equation with `odeint`, we must first convert\n",
    "    it to a system of first order equations.  By defining the angular\n",
    "    velocity ``omega(t) = theta'(t)``, we obtain the system::\n",
    "\n",
    "        theta'(t) = omega(t)\n",
    "        omega'(t) = -b*omega(t) - c*sin(theta(t))\n",
    "\n",
    "    Let `y` be the vector [`theta`, `omega`].  We implement this system\n",
    "    in python as:\n",
    "\n",
    "    >>> def pend(y, t, b, c):\n",
    "    ...     theta, omega = y\n",
    "    ...     dydt = [omega, -b*omega - c*np.sin(theta)]\n",
    "    ...     return dydt\n",
    "    ...\n",
    "\n",
    "    We assume the constants are `b` = 0.25 and `c` = 5.0:\n",
    "\n",
    "    >>> b = 0.25\n",
    "    >>> c = 5.0\n",
    "\n",
    "    For initial conditions, we assume the pendulum is nearly vertical\n",
    "    with `theta(0)` = `pi` - 0.1, and it initially at rest, so\n",
    "    `omega(0)` = 0.  Then the vector of initial conditions is\n",
    "\n",
    "    >>> y0 = [np.pi - 0.1, 0.0]\n",
    "\n",
    "    We generate a solution 101 evenly spaced samples in the interval\n",
    "    0 <= `t` <= 10.  So our array of times is:\n",
    "\n",
    "    >>> t = np.linspace(0, 10, 101)\n",
    "\n",
    "    Call `odeint` to generate the solution.  To pass the parameters\n",
    "    `b` and `c` to `pend`, we give them to `odeint` using the `args`\n",
    "    argument.\n",
    "\n",
    "    >>> from scipy.integrate import odeint\n",
    "    >>> sol = odeint(pend, y0, t, args=(b, c))\n",
    "\n",
    "    The solution is an array with shape (101, 2).  The first column\n",
    "    is `theta(t)`, and the second is `omega(t)`.  The following code\n",
    "    plots both components.\n",
    "\n",
    "    >>> import matplotlib.pyplot as plt\n",
    "    >>> plt.plot(t, sol[:, 0], 'b', label='theta(t)')\n",
    "    >>> plt.plot(t, sol[:, 1], 'g', label='omega(t)')\n",
    "    >>> plt.legend(loc='best')\n",
    "    >>> plt.xlabel('t')\n",
    "    >>> plt.grid()\n",
    "    >>> plt.show()\n",
    "```    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
